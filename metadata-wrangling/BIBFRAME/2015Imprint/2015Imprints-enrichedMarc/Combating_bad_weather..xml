<collection xmlns="http://www.loc.gov/MARC21/slim">
   <record>
      <leader>06236nam a2200601 i 4500</leader>
      <controlfield tag="001">6790079</controlfield>
      <controlfield tag="005">20150117143140.0</controlfield>
      <controlfield tag="006">m    eo  d        </controlfield>
      <controlfield tag="007">cr cn |||m|||a</controlfield>
      <controlfield tag="008">150117s2015    caua   foab   000 0 eng d</controlfield>
      <datafield ind1=" " ind2=" " tag="020">
         <subfield code="a">9781627055871</subfield>
         <subfield code="q">ebook</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="020">
         <subfield code="z">9781627055864</subfield>
         <subfield code="q">print</subfield>
      </datafield>
      <datafield ind1="7" ind2=" " tag="024">
         <subfield code="a">10.2200/S00601ED1V01Y201410IVM017</subfield>
         <subfield code="2">doi</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="035">
         <subfield code="a">ocn900303151</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="039">
         <subfield code="a">exclude</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="040">
         <subfield code="a">CaBNVSL</subfield>
         <subfield code="b">eng</subfield>
         <subfield code="e">rda</subfield>
         <subfield code="c">CaBNVSL</subfield>
         <subfield code="d">CaBNVSL</subfield>
         <subfield code="d">AEU</subfield>
      </datafield>
      <datafield ind1=" " ind2="4" tag="050">
         <subfield code="a">TA1637</subfield>
         <subfield code="b">.M8532 2015</subfield>
      </datafield>
      <datafield ind1="0" ind2="4" tag="082">
         <subfield code="a">621.367</subfield>
         <subfield code="2">23</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="090">
         <subfield code="a">Internet Access</subfield>
         <subfield code="b">AEU</subfield>
      </datafield>
      <datafield ind1="1" ind2=" " tag="100">
         <subfield code="a">Mukhopadhyay, Sudipta.,</subfield>
         <subfield code="e">author.</subfield>
         <subfield code="0">http://id.loc.gov/authorities/names/n2008205039</subfield>
         <subfield code="0">http://viaf.org/viaf/19164872</subfield>
      </datafield>
      <datafield ind1="1" ind2="0" tag="245">
         <subfield code="a">Combating bad weather.</subfield>
         <subfield code="n">Part II,</subfield>
         <subfield code="p">Fog removal from image and video /</subfield>
         <subfield code="c">Sudipta Mukhopadhyay, Abhishek Kumar Tripathi.</subfield>
      </datafield>
      <datafield ind1="3" ind2="0" tag="246">
         <subfield code="a">Fog removal from image and video.</subfield>
      </datafield>
      <datafield ind1=" " ind2="1" tag="264">
         <subfield code="a">San Rafael, California (1537 Fourth Street, San Rafael, CA  94901 USA) :</subfield>
         <subfield code="b">Morgan &amp; Claypool,</subfield>
         <subfield code="c">2015.</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="300">
         <subfield code="a">1 online resource (xiii, 70 pages) :</subfield>
         <subfield code="b">illustrations.</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="336">
         <subfield code="a">text</subfield>
         <subfield code="2">rdacontent</subfield>
         <subfield code="0">http://id.loc.gov/vocabulary/contentTypes/txt</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="337">
         <subfield code="a">electronic</subfield>
         <subfield code="2">isbdmedia</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="338">
         <subfield code="a">online resource</subfield>
         <subfield code="2">rdacarrier</subfield>
         <subfield code="0">http://id.loc.gov/vocabulary/carriers/cr</subfield>
      </datafield>
      <datafield ind1="1" ind2=" " tag="490">
         <subfield code="a">Synthesis lectures on image, video, and multimedia processing,</subfield>
         <subfield code="x">1559-8144 ;</subfield>
         <subfield code="v"># 17</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="500">
         <subfield code="a">Part of: Synthesis digital library of engineering and computer science.</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="504">
         <subfield code="a">Includes bibliographical references (pages 66-69).</subfield>
      </datafield>
      <datafield ind1="0" ind2=" " tag="505">
         <subfield code="a">1. Introduction -- 1.1 Video post-processing -- 1.2 Motivation --</subfield>
      </datafield>
      <datafield ind1="8" ind2=" " tag="505">
         <subfield code="a">2. Analysis of fog -- 2.1 Overview -- 2.1.1 Framework --</subfield>
      </datafield>
      <datafield ind1="8" ind2=" " tag="505">
         <subfield code="a">3. Dataset and performance metrics -- 3.1 Foggy images and videos -- 3.2 Performance metrics -- 3.2.1 Contrast gain (Cgain) -- 3.2.2 Percentage of the number of saturated pixels -- 3.2.3 Computation time -- 3.2.4 Root mean square (RMS) error -- 3.2.5 Perceptual quality metric (PQM) --</subfield>
      </datafield>
      <datafield ind1="8" ind2=" " tag="505">
         <subfield code="a">4. Important fog removal algorithms -- 4.1 Enhancement-based methods -- 4.2 Restoration-based methods -- 4.2.1 Multiple image-based restoration techniques -- 4.2.2 Single image-based restoration techniques --</subfield>
      </datafield>
      <datafield ind1="8" ind2=" " tag="505">
         <subfield code="a">5. Single-image fog removal using an anisotropic diffusion -- 5.1 Introduction -- 5.2 Fog removal algorithm -- 5.2.1 Initialization of airlight map -- 5.2.2 Airlight map refinement -- 5.2.3 Behavior of anisotropic diffusion -- 5.2.4 Restoration -- 5.2.5 Post-processing -- 5.3 Simulation and results -- 5.4 Conclusion --</subfield>
      </datafield>
      <datafield ind1="8" ind2=" " tag="505">
         <subfield code="a">6. Video fog removal framework using an uncalibrated single camera system -- 6.1 Introduction -- 6.2 Challenges of realtime implementation -- 6.3 Video fog removal framework -- 6.3.1 MPEG coding -- 6.4 Simulation and results -- 6.5 Conclusion --</subfield>
      </datafield>
      <datafield ind1="8" ind2=" " tag="505">
         <subfield code="a">7. Conclusions and future directions -- Bibliography -- Authors' biographies.</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="506">
         <subfield code="a">Access restricted to authorized users and institutions.</subfield>
      </datafield>
      <datafield ind1="3" ind2=" " tag="520">
         <subfield code="a">Every year lives and properties are lost in road accidents. About one-fourth of these accidents are due to low vision in foggy weather. At present, there is no algorithm that is specifically designed for the removal of fog from videos. Application of a single-image fog removal algorithm over each video frame is a time-consuming and costly affair. It is demonstrated that with the intelligent use of temporal redundancy, fog removal algorithms designed for a single image can be extended to the real-time video application. Results confirm that the presented framework used for the extension of the fog removal algorithms for images to videos can reduce the complexity to a great extent with no loss of perceptual quality. This paves the way for the real-life application of the video fog removal algorithm. In order to remove fog, an efficient fog removal algorithm using anisotropic diffusion is developed. The presented fog removal algorithm uses new dark channel assumption and anisotropic diffusion for the initialization and refinement of the airlight map, respectively. Use of anisotropic diffusion helps to estimate the better airlight map estimation. The said fog removal algorithm requires a single image captured by uncalibrated camera system. The anisotropic diffusion-based fog removal algorithm can be applied in both RGB and HSI color space. This book shows that the use of HSI color space reduces the complexity further. The said fog removal algorithm requires pre- and post-processing steps for the better restoration of the foggy image. These pre- and post-processing steps have either data-driven or constant parameters that avoid the user intervention. Presented fog removal algorithm is independent of the intensity of the fog, thus even in the case of the heavy fog presented algorithm performs well. Qualitative and quantitative results confirm that the presented fog removal algorithm outperformed previous algorithms in terms of perceptual quality, color fidelity and execution time. The work presented in this book can find wide application in entertainment industries, transportation, tracking and consumer electronics.</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="588">
         <subfield code="a">Title from PDF title page (viewed on January 17, 2015).</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="596">
         <subfield code="a">44</subfield>
      </datafield>
      <datafield ind1=" " ind2="0" tag="650">
         <subfield code="a">Image processing</subfield>
         <subfield code="x">Digital techniques.</subfield>
         <subfield code="0">http://id.loc.gov/authorities/subjects/sh85064447</subfield>
      </datafield>
      <datafield ind1=" " ind2="0" tag="650">
         <subfield code="a">Digital video.</subfield>
         <subfield code="0">http://id.loc.gov/authorities/subjects/sh94007636</subfield>
      </datafield>
      <datafield ind1=" " ind2="0" tag="650">
         <subfield code="a">Computer vision.</subfield>
         <subfield code="0">http://id.loc.gov/authorities/subjects/sh85029549</subfield>
      </datafield>
      <datafield ind1=" " ind2="0" tag="650">
         <subfield code="a">Fog</subfield>
         <subfield code="x">Pictorial works.</subfield>
      </datafield>
      <datafield ind1="1" ind2=" " tag="700">
         <subfield code="a">Tripathi, Abhishek Kumar.,</subfield>
         <subfield code="e">author.</subfield>
         <subfield code="0">http://id.loc.gov/authorities/names/no2015006261</subfield>
         <subfield code="0">http://viaf.org/viaf/313496974</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="758">
         <subfield code="0">http://worldcat.org/entity/work/id/24392468</subfield>
      </datafield>
      <datafield ind1="0" ind2=" " tag="787">
         <subfield code="n">OCLC Work Id</subfield>
         <subfield code="o">http://worldcat.org/entity/work/id/24392468</subfield>
      </datafield>
      <datafield ind1=" " ind2="0" tag="830">
         <subfield code="a">Synthesis digital library of engineering and computer science.</subfield>
         <subfield code="0">http://id.loc.gov/authorities/names/n2016188085</subfield>
      </datafield>
      <datafield ind1=" " ind2="0" tag="830">
         <subfield code="a">Synthesis lectures on image, video, and multimedia processing ;</subfield>
         <subfield code="v"># 17.</subfield>
         <subfield code="x">1559-8144</subfield>
      </datafield>
      <datafield ind1="4" ind2="0" tag="856">
         <subfield code="3">University of Alberta Access</subfield>
         <subfield code="u">http://dx.doi.org/10.2200/S00601ED1V01Y201410IVM017</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="949">
         <subfield code="h">UAIN</subfield>
         <subfield code="z">SYNTHDIG</subfield>
      </datafield>
      <datafield ind1=" " ind2=" " tag="926">
         <subfield code="a">Internet Access</subfield>
         <subfield code="w">LC</subfield>
         <subfield code="c">1</subfield>
         <subfield code="i">6790079-1001</subfield>
         <subfield code="l">INTERNET</subfield>
         <subfield code="m">UAINTERNET</subfield>
         <subfield code="r">Y</subfield>
         <subfield code="s">Y</subfield>
         <subfield code="t">E-RESOURCE</subfield>
         <subfield code="u">1/28/2015</subfield>
         <subfield code="x">E-BOOK</subfield>
         <subfield code="z">SYNTHDIG</subfield>
      </datafield>
   </record>
</collection>
