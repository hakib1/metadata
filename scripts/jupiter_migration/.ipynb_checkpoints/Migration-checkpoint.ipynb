{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  MAIN CONTROLLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from config import sparqlTerms, mig_ns, sparql_mig_test, sparql_mig_simple, sparql_mig_dev, vocabs, types\n",
    "from SPARQLWrapper import JSON, SPARQLWrapper\n",
    "from utilities import removeNS, PrintException, cleanOutputs\n",
    "import re, os, concurrent.futures, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():    \n",
    "    #  Iterate over every type of object that needs to be migrated. \n",
    "    #  This is the first splitting of the data for migration.\n",
    "    cleanOutputs(types)\n",
    "    for ptype in types:\n",
    "        # a queryObject knows where it came from.\n",
    "        # a queryObject has been split into multiple groups\n",
    "        # only one group exists for community, and one for collection objects\n",
    "        # approximately a thousand queries each are minted for thesis and for generic objects\n",
    "        # these queries are based on the first folder in the fedora pair tree\n",
    "   \n",
    "        queryObject = QueryFactory.getMigrationQuery(ptype, sparqlData=sparql_mig_simple)\n",
    "        print('%s batch queries generated' % (ptype))\n",
    "        print('%i batch(es) of %s objects to be transformed' % (len(queryObject.queries), ptype))\n",
    "        i = 0\n",
    "        for group in queryObject.queries.keys():\n",
    "            i = i + 1\n",
    "            DTO = DataFactory.getData(queryObject.queries[group], group, queryObject) # query, group, object\n",
    "            DTO.transformData()\n",
    "            print(\"%i of %i %s batches transformed\" % (i, len(queryObject.queries), ptype) )\n",
    "        print(\"%s objects transformation completed\" % (ptype) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TRANSFORMATIONS\n",
    "#### functions for handling data passed over by the data object. Takes a triple, detects what kind of action needs to be taken based on the predicate, sends it to the appropriate function for transformations, then returns it back to the data handler to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Transformation():\n",
    "    \n",
    "    \"\"\"\n",
    "    the output must be a list of triples matching the same format as the input (as follows):\n",
    "    \n",
    "    {\n",
    "        'subject': {\n",
    "            'value': 'http://gillingham.library.ualberta.ca:8080/fedora/rest/prod/0r/96/76/28/0r967628d', \n",
    "            'type': 'uri'\n",
    "        }, \n",
    "        'predicate': {\n",
    "            'value': 'http://purl.org/dc/elements/1.1/subject', \n",
    "            'type': 'uri'\n",
    "        }, \n",
    "        'object': {\n",
    "            'value': 'Geochemistry', \n",
    "            'type': 'literal'\n",
    "        }\n",
    "    }\n",
    "    output is appended to self.output\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.output = []\n",
    "        \n",
    "    ############################################################################\n",
    "    ######################## transformation on rdf:type ########################\n",
    "    ############################################################################\n",
    "        \n",
    "    def rdfsyntaxnstype(self, triple, ptype):\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "\n",
    "       \n",
    "    ############################################################################\n",
    "    ######################## transformation on dcterms:language ################\n",
    "    ############################################################################\n",
    "\n",
    "    def language(self, triple, ptype):\n",
    "        # normalize values and convert to URI (consult the \"vocabs\" variable from the config file (this folder))\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "\n",
    "\n",
    "    ############################################################################\n",
    "    ######################## transformation on dc:rights #######################\n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "    def rights(self, triple, ptype):\n",
    "        #### \n",
    "        # several different license values need to be coerced into one common value, this needs to be confirmed with leah before it is written\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "\n",
    "    \n",
    "    ############################################################################\n",
    "    ######################## transformation on ual:institution #################\n",
    "    ############################################################################\n",
    "\n",
    "    def institution(self, triple, ptype):\n",
    "        # convert university of alberta to <http://id.loc.gov/authorities/names/n79058482>\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    " \n",
    "\n",
    "    ############################################################################\n",
    "    ######################## transformation on dcterms:license #################\n",
    "    ############################################################################\n",
    "\n",
    "    \n",
    "    def license(self, triple, ptype):\n",
    "        #### \n",
    "        # convert licenses from text to URI (use vocabs variable, some coersion will be necessary)\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    ######################## transformation on dcterms:type ####################\n",
    "    ############################################################################\n",
    "    \n",
    "    def type(self, triple, ptype):      \n",
    "        if ptype == 'batch':\n",
    "                # null\n",
    "                # Complete\n",
    "                # processing\n",
    "            self.output.append(\n",
    "                 {\n",
    "                    'subject': {\n",
    "                        'value': triple['subject']['value'], # the subject of the triple\n",
    "                        'type': 'uri'\n",
    "                    }, \n",
    "                    'predicate': {\n",
    "                        'value': \"a different predicate\", # the predicate of the triple\n",
    "                        'type': 'uri'\n",
    "                    }, \n",
    "                    'object': {\n",
    "                        'value': triple['object']['value'], # mapped uri\n",
    "                        'type': 'uri'\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        if ptype == 'thesis':\n",
    "            # nothing needs to happen\n",
    "            pass\n",
    "        elif ptype == 'generic':\n",
    "            for vocab in vocabs[\"type\"]:\n",
    "                # mint a new triple with the mapped type\n",
    "                if triple['object']['value'] in vocab[\"mapping\"]:\n",
    "                    self.output.append(\n",
    "                        {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': triple['predicate']['value'], # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value': vocab[\"uri\"], # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        }\n",
    "                    )\n",
    "                if \"Draft-Submitted\" in triple['object']['value']:\n",
    "                    self.output.append( \n",
    "                        {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': \"http://purl.org/ontology/bibo/status\", # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value': \"http://vivoweb.org/ontology/core#submitted\", # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        }\n",
    "                    )\n",
    "                    self.output.append(\n",
    "                         {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': \"http://purl.org/ontology/bibo/status\", # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value': \"http://purl.org/ontology/bibo/status#draft\", # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        }\n",
    "                    )\n",
    "                if \"Published\" in triple['object']['value']:\n",
    "                    self.output.append( \n",
    "                         {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': \"http://purl.org/ontology/bibo/status\", # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value': \"http://purl.org/ontology/bibo/status#published\", # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        }\n",
    "                    )\n",
    "        elif (ptype == 'community') or (ptype == 'collection'):\n",
    "            self.output.append(triple)\n",
    "        \n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  QUERY BUILDER\n",
    "##### Pulls current mappings from triplestore, dynamically builds queries in managable sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Query(object):\n",
    "    \"\"\" Query objects are dynamically generated, and contain SPARQL CONSTRUCT queries with input from the jupiter application profile \"\"\"\n",
    "    def __init__(self, ptype, sparqlData, sparqlTerms=sparqlTerms):\n",
    "        self.mapping = []\n",
    "        self.sparqlTerms = SPARQLWrapper(sparqlTerms)  # doesn't need to change (the terms store doesn't change)\n",
    "        self.sparqlData = SPARQLWrapper(sparqlData)  # sets the triple store from which to get data (simple, test, or dev)\n",
    "        self.endpoint = sparqlData\n",
    "        self.queries = {}\n",
    "        self.splitBy = {}\n",
    "        self.prefixes = \"\"\n",
    "        self.filename = \"\"\n",
    "        for ns in mig_ns:\n",
    "            self.prefixes = self.prefixes + \" PREFIX %s: <%s> \" % (ns['prefix'], ns['uri'])\n",
    "        self.getMappings()\n",
    "        self.generateQueries()\n",
    "\n",
    "    def getMappings(self):\n",
    "        query = \"prefix ual: <http://terms.library.ualberta.ca/>SELECT * WHERE {GRAPH ual:%s {?newProperty ual:backwardCompatibleWith ?oldProperty} }\" % (self.ptype)\n",
    "        self.sparqlTerms.setReturnFormat(JSON)\n",
    "        self.sparqlTerms.setQuery(query)\n",
    "        results = self.sparqlTerms.query().convert()\n",
    "        for result in results['results']['bindings']:\n",
    "            self.mapping.append((result['newProperty']['value'], result['oldProperty']['value']))\n",
    "\n",
    "    def getSplitBy(self):\n",
    "        # base query only needs 3 prefixes appended to the \"select\" statement defined by the object\n",
    "        query = \"prefix dcterm: <http://purl.org/dc/terms/> prefix info: <info:fedora/fedora-system:def/model#> prefix ual: <http://terms.library.ualberta.ca/> %s\" % (self.select)\n",
    "        self.sparqlData.setReturnFormat(JSON)\n",
    "        self.sparqlData.setQuery(query)\n",
    "        results =  self.sparqlData.query().convert()\n",
    "        # iterate over query results\n",
    "        for result in results['results']['bindings']:\n",
    "            # the group is the two folders at the base of the pair tree, concatenated by an underscore\n",
    "            group = result['resource']['value'].split('/')[6]\n",
    "            # assign that parameter by which you want to search to that group\n",
    "            self.splitBy[group] = \"/\".join( result['resource']['value'].split('/')[:7] )# the stem of the resource [0] and the group number by which to save [1] (this is the first digit in the pair tree)\n",
    "            \n",
    "\n",
    "    def generateQueries(self):\n",
    "        pass\n",
    "    \n",
    "    def writeQueries(self):\n",
    "        filename = \"cache/%s.json\" % (self.ptype)\n",
    "        with open(filename, 'w+') as f:\n",
    "            json.dump([self.queries], f)\n",
    "               \n",
    "class Collection(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.ptype = 'collection'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Collection\"\n",
    "        self.where = [\"WHERE { ?resource info:hasModel 'Collection'^^xsd:string . OPTIONAL { ?resource ualids:is_community 'false'^^xsd:boolean } . OPTIONAL { ?resource ualid:is_community 'false'^^xsd:boolean } . OPTIONAL { ?resource ual:is_community 'false'^^xsd:boolean }\"]\n",
    "        self.select = None\n",
    "        super().__init__(self.ptype, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        for where in self.where:\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], removeNS(pair[0]))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (?%s!='') }\" % (where, pair[1], removeNS(pair[0]), removeNS(pair[0]))\n",
    "            self.queries['collection'] = \"%s %s } %s }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries\n",
    "\n",
    "class Community(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.ptype = 'community'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Object; rdf:type ual:Community\"\n",
    "        self.where = [\"WHERE { ?resource info:hasModel 'Collection'^^xsd:string ; OPTIONAL { ?resource ualids:is_community 'true'^^xsd:boolean } . OPTIONAL { ?resource ualid:is_community 'true'^^xsd:boolean } . OPTIONAL { ?resource ual:is_community 'true'^^xsd:boolean }\"]\n",
    "        self.select = None\n",
    "        super().__init__(self.ptype, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        for where in self.where:\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], removeNS(pair[0]))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (?%s!='') }\" % (where, pair[1], removeNS(pair[0]), removeNS(pair[0]))\n",
    "            self.queries['community'] = \"%s %s } %s }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries()\n",
    "\n",
    "class Generic(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.ptype = 'generic'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Object; rdf:type works:work\"\n",
    "        self.where = []\n",
    "        self.select = \"SELECT distinct ?resource WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type ?type . filter(?type != 'Thesis'^^xsd:string) }\"\n",
    "        super().__init__(self.ptype, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        query = \"%s %s\" % (self.prefixes, self.select)\n",
    "        for group in self.splitBy.keys():\n",
    "            where = \"WHERE {  ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type ?type . filter(?type != 'Thesis'^^xsd:string) . FILTER (contains(str(?resource), '%s'))\" % (self.splitBy[group])\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], removeNS(pair[0]))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (?%s!='') }\" % (where, pair[1], removeNS(pair[0]), removeNS(pair[0]))\n",
    "            self.queries[group] = \"%s %s } %s }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries()\n",
    "\n",
    "\n",
    "class Thesis(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.ptype = 'thesis'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Object; rdf:type works:work ; rdf:type bibo:Thesis\"\n",
    "        self.where = []\n",
    "        self.select = \"SELECT distinct ?resource WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type 'Thesis'^^xsd:string }\"\n",
    "        super().__init__(self.ptype, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()        \n",
    "        query = \"%s %s\" % (self.prefixes, self.select)\n",
    "        for group in self.splitBy.keys():\n",
    "            where = \"WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type 'Thesis'^^xsd:string . FILTER (contains(str(?resource), '%s'))\" % (self.splitBy[group])\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], removeNS(pair[0]))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (?%s!='') }\" % (where, pair[1], removeNS(pair[0]), removeNS(pair[0]))\n",
    "                self.queries[group] =  \"%s %s } %s  }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries()\n",
    "\n",
    "\n",
    "class Batch(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.ptype = 'batch'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'Batch' ; schema:result ?type; ?predicate ?object }\"\n",
    "        self.where = \"WHERE { ?resource info:hasModel 'Batch'^^xsd:string ; \"\n",
    "        self.select = \"SELECT distinct ?resource WHERE  { ?resource info:hasModel 'Batch'^^xsd:string } \"\n",
    "        super().__init__(self.ptype, sparqlData)\n",
    "    \n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        for group in self.splitBy.keys():\n",
    "            self.queries[group] = \"%s %s %s FILTER (contains(str(?resource), '%s')) . ?resource dcterm:type ?type . ?resource ?predicate ?object . FILTER (?object!='') }\" % (self.prefixes, self.construct, self.where, self.splitBy[group])\n",
    "        self.writeQueries()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  DATA TRANSPORT OBJECTS\n",
    "##### Runs a query, sends data to get transformed, saves data to appropriate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    def __init__(self, query, group, sparqlData, sparqlTerms, ptype):\n",
    "        self.q = query\n",
    "        self.group = group\n",
    "        self.sparqlData = sparqlData\n",
    "        self.sparqlTerms = sparqlTerms\n",
    "        self.output = []\n",
    "        self.ptype = type\n",
    "        self.directory = \"results/%s/\" % (ptype)\n",
    "        self.filename = \"results/%s/%s.nt\" % (ptype, group)\n",
    "        if not os.path.exists(self.directory):\n",
    "            os.makedirs(self.directory)\n",
    "        \n",
    "\n",
    "    def transformData(self):\n",
    "        self.sparqlData.setMethod(\"GET\")\n",
    "        self.sparqlData.setReturnFormat(JSON)\n",
    "        self.sparqlData.setQuery(self.q)\n",
    "        results = self.sparqlData.query().convert()['results']['bindings']\n",
    "        for result in results:\n",
    "            result = TransformationFactory().getTransformation(result, self.ptype)\n",
    "            if isinstance(result, list):\n",
    "                for triple in result:\n",
    "                    s = \"<%s>\" % (str(triple['subject']['value']))\n",
    "                    p = \"<%s>\" % (str(triple['predicate']['value']))\n",
    "                    if triple['object']['type'] == 'uri':\n",
    "                        o = \"<%s>\" % (str(triple['object']['value']))\n",
    "                    else:\n",
    "                        o = \"\\\"%s\\\"\" % (str(triple['object']['value']))\n",
    "                    self.output.append(\"%s %s %s . \\n\" % (s, p, o))\n",
    "        with open(self.filename, \"w+\") as f:\n",
    "            f.writelines(self.output)\n",
    "\n",
    "        #with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
    "        #    future_to_result = {executor.submit(self.processResults, results, query): result for result in results}\n",
    "        #    for future in concurrent.futures.as_completed(future_to_result):\n",
    "        #        result = future_to_result[future]\n",
    "        #        try:\n",
    "        #            future.result()\n",
    "        #        except Exception:\n",
    "        #            PrintException()\n",
    "\n",
    "class CollectionData(Data):\n",
    "    def __init__(self, q, group, sparqlData, sparqlTerms, ptype):\n",
    "        super().__init__(q, group, sparqlData, sparqlTerms, ptype)\n",
    "\n",
    "class CommunityData(Data):\n",
    "    def __init__(self, q, group, sparqlData, sparqlTerms, ptype):\n",
    "        super().__init__(q, group, sparqlData, sparqlTerms, ptype)\n",
    "\n",
    "class ThesisData(Data):\n",
    "    def __init__(self, q, group, sparqlData, sparqlTerms, ptype):\n",
    "        super().__init__(q, group, sparqlData, sparqlTerms, ptype)             \n",
    "\n",
    "class GenericData(Data):\n",
    "    def __init__(self, q, group, sparqlData, sparqlTerms, ptype):\n",
    "        super().__init__(q, group, sparqlData, sparqlTerms, ptype)        \n",
    "\n",
    "class BatchData(Data):\n",
    "    def __init__(self, q, group, sparqlData, sparqlTerms, ptype):\n",
    "        super().__init__(q, group, sparqlData, sparqlTerms, ptype)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class QueryFactory():\n",
    "    @staticmethod\n",
    "    def getMigrationQuery(ptype, sparqlData):\n",
    "        \"\"\" returns a specified query object depending on the type passed in\"\"\"\n",
    "        if ptype == \"collection\": return Collection(sparqlData)\n",
    "        elif ptype == \"community\": return Community(sparqlData) \n",
    "        elif ptype == \"thesis\": return Thesis(sparqlData)\n",
    "        elif ptype == \"generic\": return Generic(sparqlData)\n",
    "        elif ptype == \"batch\": return Batch(sparqlData)\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataFactory():\n",
    "    @staticmethod\n",
    "    def getData(query, group, queryObject):\n",
    "        \"\"\" returns a specified query object depending on the type passed in\"\"\"\n",
    "        functions = {\"collection\": CollectionData(query, group, queryObject.sparqlData, queryObject.sparqlTerms, queryObject.ptype), \n",
    "                     \"community\": CommunityData(query, group, queryObject.sparqlData, queryObject.sparqlTerms, queryObject.ptype), \n",
    "                     \"thesis\": ThesisData(query, group, queryObject.sparqlData, queryObject.sparqlTerms, queryObject.ptype), \n",
    "                     \"generic\": GenericData(query, group, queryObject.sparqlData, queryObject.sparqlTerms, queryObject.ptype), \n",
    "                     \"batch\": BatchData(query, group, queryObject.sparqlData, queryObject.sparqlTerms, queryObject.ptype)\n",
    "                    }\n",
    "        if queryObject.ptype in functions:\n",
    "            return functions[queryObject.ptype]\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TransformationFactory():\n",
    "    @staticmethod\n",
    "    def getTransformation(triple, ptype):\n",
    "        function = re.sub(r'[0-9]+', '', triple['predicate']['value'].split('/')[-1].replace('#', '').replace('-', ''))\n",
    "        if function == \"rdfsyntaxnstype\": return Transformation().rdfsyntaxnstype(triple, ptype)\n",
    "        elif function == \"language\": return Transformation().language(triple, ptype)\n",
    "        elif function == \"type\": return Transformation().type(triple, ptype)\n",
    "        elif function ==  \"rights\": return Transformation().rights(triple, ptype)\n",
    "        elif function == \"license\": return Transformation().license(triple, ptype)\n",
    "        else:\n",
    "            return [triple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'sparqlData'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-184-aa7afb95b669>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m         \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-177-410de6c4265a>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# these queries are based on the first folder in the fedora pair tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mqueryObject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQueryFactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetMigrationQuery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparqlData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msparql_mig_simple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s batch queries generated'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mptype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%i batch(es) of %s objects to be transformed'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueryObject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mptype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-181-235d886992e6>\u001b[0m in \u001b[0;36mgetMigrationQuery\u001b[1;34m(ptype, sparqlData)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetMigrationQuery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparqlData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;34m\"\"\" returns a specified query object depending on the type passed in\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mptype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"collection\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mCollection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparqlData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mptype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"community\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mCommunity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparqlData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mptype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"thesis\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mThesis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparqlData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-179-907a398547c5>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sparqlData)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"WHERE { ?resource info:hasModel 'Collection'^^xsd:string . OPTIONAL { ?resource ualids:is_community 'false'^^xsd:boolean } . OPTIONAL { ?resource ualid:is_community 'false'^^xsd:boolean } . OPTIONAL { ?resource ual:is_community 'false'^^xsd:boolean }\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mptype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerateQueries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'sparqlData'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
