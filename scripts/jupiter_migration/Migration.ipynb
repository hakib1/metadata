{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  MAIN CONTROLLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import sparqlTerms, mig_ns, sparql_mig_test, sparql_mig_simple, sparql_mig_dev, vocabs, types\n",
    "from SPARQLWrapper import JSON, SPARQLWrapper\n",
    "from utilities import removeNS, PrintException, cleanOutputs\n",
    "import re, os, concurrent.futures, json, requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    #  Iterate over every type of object that needs to be migrated. \n",
    "    #  This is the first splitting of the data for migration.\n",
    "    cleanOutputs(types)\n",
    "    for ptype in types:\n",
    "        # a queryObject knows where it came from.\n",
    "        # a queryObject has been split into multiple groups\n",
    "        # only one group exists for community, and one for collection objects\n",
    "        # approximately a thousand queries each are minted for thesis and for generic objects\n",
    "        # these queries are based on the first folder in the fedora pair tree\n",
    "        queryObject = QueryFactory.getMigrationQuery(ptype, sparqlData=sparql_mig_test)\n",
    "        print('%s batch queries generated' % (ptype))\n",
    "        print('%i batch(es) of %s objects to be transformed' % (len(queryObject.queries), ptype))\n",
    "        i = 0\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
    "            \n",
    "            future_to_result = {executor.submit(parellelTransform, queryObject, group): group for group in queryObject.queries.keys()}\n",
    "            for future in concurrent.futures.as_completed(future_to_result):\n",
    "                result = future_to_result[future]\n",
    "                try:\n",
    "                    i = i + 1\n",
    "                    future.result()\n",
    "                    print(\"%i of %i %s batches transformed\" % (i, len(queryObject.queries), ptype) )\n",
    "                except Exception:\n",
    "                    PrintException()\n",
    "        print(\"%s objects transformation completed\" % (ptype) )\n",
    "\n",
    "def parellelTransform(queryObject, group):\n",
    "    DTO = DataFactory.getData(queryObject.queries[group], group, queryObject) # query, group, object\n",
    "    DTO.transformData()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TRANSFORMATIONS\n",
    "#### functions for handling data passed over by the data object. Takes a triple, detects what kind of action needs to be taken based on the predicate, sends it to the appropriate function for transformations, then returns it back to the data handler to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Transformation():\n",
    "    \n",
    "    \"\"\"\n",
    "    the output must be a list of triples matching the same format as the input (as follows):\n",
    "    \n",
    "    {\n",
    "        'subject': {\n",
    "            'value': 'http://gillingham.library.ualberta.ca:8080/fedora/rest/prod/0r/96/76/28/0r967628d', \n",
    "            'type': 'uri'\n",
    "        }, \n",
    "        'predicate': {\n",
    "            'value': 'http://purl.org/dc/elements/1.1/subject', \n",
    "            'type': 'uri'\n",
    "        }, \n",
    "        'object': {\n",
    "            'value': 'Geochemistry', \n",
    "            'type': 'literal'\n",
    "        }\n",
    "    }\n",
    "    output is appended to self.output\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.output = []\n",
    "        \n",
    "    ############################################################################\n",
    "    ######################## transformation on rdf:type ########################\n",
    "    ############################################################################\n",
    "        \n",
    "    def rdfsyntaxnstype(self, triple, ptype):\n",
    "        \n",
    "        ### this is an important transformation:\n",
    "        \n",
    "                # \n",
    "        \n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "\n",
    "       \n",
    "    ############################################################################\n",
    "    ######################## transformation on dcterms:language ################\n",
    "    ############################################################################\n",
    "\n",
    "    def language(self, triple, ptype):\n",
    "        # normalize values and convert to URI (consult the \"vocabs\" variable from the config file (this folder))\n",
    "        for vocab in vocabs[\"language\"]:\n",
    "            # mint a new triple with the mapped type\n",
    "            if triple['object']['value'] in  vocab[\"mapping\"]:\n",
    "                self.output.append(\n",
    "                    {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': triple['predicate']['value'], # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value': vocab[\"uri\"], # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        } \n",
    "                    ) \n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "\n",
    "\n",
    "    ############################################################################\n",
    "    ######################## transformation on dc:rights #######################\n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "    def rights(self, triple, ptype):\n",
    "        #### \n",
    "        # several different license values need to be coerced into one common value, this needs to be confirmed with leah before it is written\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "\n",
    "    \n",
    "    ############################################################################\n",
    "    ######################## transformation on ual:institution #################\n",
    "    ############################################################################\n",
    "\n",
    "    def institution(self, triple, ptype):\n",
    "        self.output.append(\n",
    "            {\n",
    "            'subject': {\n",
    "                'value': triple['subject']['value'], \n",
    "                'type': 'uri'\n",
    "            }, \n",
    "            'predicate': {\n",
    "                'value': triple['predicate']['value'], \n",
    "                'type': 'uri'\n",
    "            }, \n",
    "            'object': {\n",
    "                'value': 'http://id.loc.gov/authorities/names/n79058482', \n",
    "                'type': 'uri'\n",
    "            }\n",
    "        }\n",
    "        )\n",
    "        return self.output\n",
    " \n",
    "\n",
    "    ############################################################################\n",
    "    ######################## transformation on dcterms:license #################\n",
    "    ############################################################################\n",
    "\n",
    "    \n",
    "    def license(self, triple, ptype):\n",
    "        #### \n",
    "        # convert licenses from text to URI (use vocabs variable, some coersion will be necessary)\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    ######################## transformation on dcterms:type ####################\n",
    "    ############################################################################\n",
    "    \n",
    "    def type(self, triple, ptype):\n",
    "        if ptype == 'generic':\n",
    "            for vocab in vocabs[\"type\"]:\n",
    "                # mint a new triple with the mapped type\n",
    "                if triple['object']['value'] in vocab[\"mapping\"]:\n",
    "                    self.output.append(\n",
    "                        {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': triple['predicate']['value'], # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value': vocab[\"uri\"], # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        }\n",
    "                    )\n",
    "     \n",
    "            else:\n",
    "                pass\n",
    "        elif (ptype == 'community') or (ptype == 'collection'):\n",
    "            self.output.append(triple)\n",
    "        \n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  QUERY BUILDER\n",
    "##### Pulls current mappings from triplestore, dynamically builds queries in managable sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Query(object):\n",
    "    \"\"\" Query objects are dynamically generated, and contain SPARQL CONSTRUCT queries with input from the jupiter application profile \"\"\"\n",
    "    def __init__(self, ptype, sparqlData, sparqlTerms=sparqlTerms):\n",
    "        self.mapping = []\n",
    "        self.sparqlTerms = SPARQLWrapper(sparqlTerms)  # doesn't need to change (the terms store doesn't change)\n",
    "        self.sparqlData = SPARQLWrapper(sparqlData)  # sets the triple store from which to get data (simple, test, or dev)\n",
    "        self.sparqlTerms.setMethod(\"POST\")\n",
    "        self.sparqlData.setMethod(\"POST\")\n",
    "        self.endpoint = sparqlData\n",
    "        self.queries = {}\n",
    "        self.splitBy = {}\n",
    "        self.prefixes = \"\"\n",
    "        self.filename = \"\"\n",
    "        for ns in mig_ns:\n",
    "            self.prefixes = self.prefixes + \" PREFIX %s: <%s> \" % (ns['prefix'], ns['uri'])\n",
    "        self.getMappings()\n",
    "        self.generateQueries()\n",
    "\n",
    "    def getMappings(self):\n",
    "        query = \"prefix ual: <http://terms.library.ualberta.ca/>SELECT * WHERE {GRAPH ual:%s {?newProperty ual:backwardCompatibleWith ?oldProperty} }\" % (self.ptype)\n",
    "        self.sparqlTerms.setReturnFormat(JSON)\n",
    "        self.sparqlTerms.setQuery(query)\n",
    "        results = self.sparqlTerms.query().convert()\n",
    "        for result in results['results']['bindings']:\n",
    "            self.mapping.append((result['newProperty']['value'], result['oldProperty']['value']))\n",
    "\n",
    "    def getSplitBy(self):\n",
    "        # base query only needs 3 prefixes appended to the \"select\" statement defined by the object\n",
    "        query = \"prefix dcterm: <http://purl.org/dc/terms/> prefix info: <info:fedora/fedora-system:def/model#> prefix ual: <http://terms.library.ualberta.ca/> %s\" % (self.select)\n",
    "        self.sparqlData.setReturnFormat(JSON)\n",
    "        self.sparqlData.setQuery(query)\n",
    "        results =  self.sparqlData.query().convert()\n",
    "        # iterate over query results\n",
    "        for result in results['results']['bindings']:\n",
    "            # the group is the two folders at the base of the pair tree, concatenated by an underscore\n",
    "            group = result['resource']['value'].split('/')[6]\n",
    "            # assign that parameter by which you want to search to that group\n",
    "            self.splitBy[group] = \"/\".join( result['resource']['value'].split('/')[:7] )# the stem of the resource [0] and the group number by which to save [1] (this is the first digit in the pair tree)\n",
    "            \n",
    "\n",
    "    def generateQueries(self):\n",
    "        pass\n",
    "    \n",
    "    def writeQueries(self):\n",
    "        filename = \"cache/%s.json\" % (self.ptype)\n",
    "        with open(filename, 'w+') as f:\n",
    "            json.dump([self.queries], f)\n",
    "               \n",
    "class Collection(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.ptype = 'collection'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Collection\"\n",
    "        self.where = [\"WHERE { ?resource info:hasModel 'Collection'^^xsd:string . OPTIONAL { ?resource ualids:is_community 'false'^^xsd:boolean } . OPTIONAL { ?resource ualid:is_community 'false'^^xsd:boolean } . OPTIONAL { ?resource ual:is_community 'false'^^xsd:boolean }\"]\n",
    "        self.select = None\n",
    "        super().__init__(self.ptype, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        for where in self.where:\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], removeNS(pair[0]))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (?%s!='') }\" % (where, pair[1], removeNS(pair[0]), removeNS(pair[0]))\n",
    "            self.queries['collection'] = \"%s %s } %s }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries\n",
    "\n",
    "class Community(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.ptype = 'community'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Object; rdf:type ual:Community\"\n",
    "        self.where = [\"WHERE { ?resource info:hasModel 'Collection'^^xsd:string ; OPTIONAL { ?resource ualids:is_community 'true'^^xsd:boolean } . OPTIONAL { ?resource ualid:is_community 'true'^^xsd:boolean } . OPTIONAL { ?resource ual:is_community 'true'^^xsd:boolean }\"]\n",
    "        self.select = None\n",
    "        super().__init__(self.ptype, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        for where in self.where:\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], removeNS(pair[0]))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (?%s!='') }\" % (where, pair[1], removeNS(pair[0]), removeNS(pair[0]))\n",
    "            self.queries['community'] = \"%s %s } %s }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries()\n",
    "\n",
    "class Generic(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.ptype = 'generic'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Object; rdf:type works:work\"\n",
    "        self.where = []\n",
    "        self.select = \"SELECT distinct ?resource WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type ?type . filter(?type != 'Thesis'^^xsd:string) }\"\n",
    "        super().__init__(self.ptype, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        query = \"%s %s\" % (self.prefixes, self.select)\n",
    "        for group in self.splitBy.keys():\n",
    "            where = \"WHERE {  ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type ?type . filter(?type != 'Thesis'^^xsd:string) . FILTER (contains(str(?resource), '%s'))\" % (self.splitBy[group])\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], removeNS(pair[0]))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (?%s!='') }\" % (where, pair[1], removeNS(pair[0]), removeNS(pair[0]))\n",
    "            self.queries[group] = \"%s %s } %s }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries()\n",
    "\n",
    "\n",
    "class Thesis(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.ptype = 'thesis'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Object; rdf:type works:work ; rdf:type bibo:Thesis\"\n",
    "        self.where = []\n",
    "        self.select = \"SELECT distinct ?resource WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type 'Thesis'^^xsd:string }\"\n",
    "        super().__init__(self.ptype, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()        \n",
    "        query = \"%s %s\" % (self.prefixes, self.select)\n",
    "        for group in self.splitBy.keys():\n",
    "            where = \"WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type 'Thesis'^^xsd:string . FILTER (contains(str(?resource), '%s'))\" % (self.splitBy[group])\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], removeNS(pair[0]))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (?%s!='') }\" % (where, pair[1], removeNS(pair[0]), removeNS(pair[0]))\n",
    "                self.queries[group] =  \"%s %s } %s  }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries()\n",
    "\n",
    "\n",
    "class Batch(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.ptype = 'batch'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'Batch' ; schema:result ?type; ?predicate ?object }\"\n",
    "        self.where = \"WHERE { ?resource info:hasModel 'Batch'^^xsd:string ; \"\n",
    "        self.select = \"SELECT distinct ?resource WHERE  { ?resource info:hasModel 'Batch'^^xsd:string } \"\n",
    "        super().__init__(self.ptype, sparqlData)\n",
    "    \n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        for group in self.splitBy.keys():\n",
    "            self.queries[group] = \"%s %s %s FILTER (contains(str(?resource), '%s')) . ?resource dcterm:type ?type . ?resource ?predicate ?object . FILTER (?object!='') }\" % (self.prefixes, self.construct, self.where, self.splitBy[group])\n",
    "        self.writeQueries()\n",
    "\n",
    "\n",
    "class Fedorafoxml(Query):\n",
    "    # queries remaining fedora objects that do not fall into the above model (i.e. characterization, foxml, etc.)\n",
    "    def __init__(self, sparqlData):\n",
    "        self.ptype = 'fedorafoxml'\n",
    "        self.construct = \"CONSTRUCT { ?resource rdf:type <http://www.w3.org/ns/ldp#NonRDFSource>; ?predicate object\"\n",
    "        self.where = \"WHERE { ?resource rdf:type <http://www.w3.org/ns/ldp#NonRDFSource> . FILTER (contains(?resource, 'fedorafoxml')); ?predicate object\"\n",
    "        self.select = \"SELECT distinct ?resource WHERE  {?resource rdf:type <http://www.w3.org/ns/ldp#NonRDFSource> . FILTER (contains(?resource, 'fedorafoxml')) } \"\n",
    "        super().__init__(self.ptype, sparqlData)\n",
    "        \n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        for group in self.splitBy.keys():\n",
    "            self.queries[group] = \"%s %s %s FILTER (contains(str(?resource), '%s')) . ?resource dcterm:type ?type . ?resource ?predicate ?object . FILTER (?object!='') }\" % (self.prefixes, self.construct, self.where, self.splitBy[group])\n",
    "        self.writeQueries()    \n",
    "\n",
    "class Characterization(Query):\n",
    "    # queries remaining fedora objects that do not fall into the above model (i.e. characterization, foxml, etc.)\n",
    "    def __init__(self, sparqlData):\n",
    "        self.ptype = 'characterization'\n",
    "        self.construct = \"CONSTRUCT { ?resource rdf:type <http://www.w3.org/ns/ldp#NonRDFSource>; ?predicate object\"\n",
    "        self.where = \"WHERE { ?resource rdf:type <http://www.w3.org/ns/ldp#NonRDFSource> . FILTER (contains(?resource, 'characterization')); ?predicate object\"\n",
    "        self.select = \"SELECT distinct ?resource WHERE  {?resource rdf:type <http://www.w3.org/ns/ldp#NonRDFSource> . FILTER (contains(?resource, 'characterization')) } \"\n",
    "        super().__init__(self.ptype, sparqlData)\n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        for group in self.splitBy.keys():\n",
    "            self.queries[group] = \"%s %s %s FILTER (contains(str(?resource), '%s')) . ?resource dcterm:type ?type . ?resource ?predicate ?object . FILTER (?object!='') }\" % (self.prefixes, self.construct, self.where, self.splitBy[group])\n",
    "        self.writeQueries()    \n",
    "        \n",
    "class Content(Query):\n",
    "    # queries remaining fedora objects that do not fall into the above model (i.e. characterization, foxml, etc.)\n",
    "    def __init__(self, sparqlData):\n",
    "        self.ptype = 'content'\n",
    "        self.construct = \"CONSTRUCT { ?resource rdf:type <http://www.w3.org/ns/ldp#NonRDFSource>; ?predicate object\"\n",
    "        self.where = \"WHERE { ?resource rdf:type <http://www.w3.org/ns/ldp#NonRDFSource> . FILTER (contains(?resource, 'content')); ?predicate object\"\n",
    "        self.select = \"SELECT distinct ?resource WHERE  {?resource rdf:type <http://www.w3.org/ns/ldp#NonRDFSource> . FILTER (contains(?resource, 'content')) } \"\n",
    "        super().__init__(self.ptype, sparqlData)\n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        for group in self.splitBy.keys():\n",
    "            self.queries[group] = \"%s %s %s FILTER (contains(str(?resource), '%s')) . ?resource dcterm:type ?type . ?resource ?predicate ?object . FILTER (?object!='') }\" % (self.prefixes, self.construct, self.where, self.splitBy[group])\n",
    "        self.writeQueries()    \n",
    "    \n",
    "class Erastats1(Query):\n",
    "    # queries remaining fedora objects that do not fall into the above model (i.e. characterization, foxml, etc.)\n",
    "    def __init__(self, sparqlData):\n",
    "        self.ptype = 'erastats1'\n",
    "        self.construct = \"CONSTRUCT { ?resource rdf:type <http://www.w3.org/ns/ldp#NonRDFSource>; ?predicate object\"\n",
    "        self.where = \"WHERE { ?resource rdf:type <http://www.w3.org/ns/ldp#NonRDFSource> . FILTER (contains(?resource, 'erastats1')); ?predicate object\"\n",
    "        self.select = \"SELECT distinct ?resource WHERE  {?resource rdf:type <http://www.w3.org/ns/ldp#NonRDFSource> . FILTER (contains(?resource, 'erastats1')) } \"\n",
    "        super().__init__(self.ptype, sparqlData)\n",
    "        \n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        for group in self.splitBy.keys():\n",
    "            self.queries[group] = \"%s %s %s FILTER (contains(str(?resource), '%s')) . ?resource dcterm:type ?type . ?resource ?predicate ?object . FILTER (?object!='') }\" % (self.prefixes, self.construct, self.where, self.splitBy[group])\n",
    "        self.writeQueries()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  DATA TRANSPORT OBJECTS\n",
    "##### Runs a query, sends data to get transformed, saves data to appropriate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    def __init__(self, query, group, sparqlData, sparqlTerms, queryObject):\n",
    "        self.q = query\n",
    "        self.group = group\n",
    "        self.sparqlData = sparqlData\n",
    "        self.sparqlTerms = sparqlTerms\n",
    "        self.output = []\n",
    "        self.streamOut = []\n",
    "        self.ptype = queryObject.ptype\n",
    "        self.directory = \"results/%s/\" % (self.ptype)\n",
    "        self.filename = \"results/%s/%s.nt\" % (self.ptype, group)\n",
    "        if not os.path.exists(self.directory):\n",
    "            os.makedirs(self.directory)\n",
    "        \n",
    "\n",
    "    def transformData(self):\n",
    "        self.sparqlData.setReturnFormat(JSON)\n",
    "        self.sparqlData.setQuery(self.q)\n",
    "        # queries a batch of resources from this particular \"group\"\n",
    "        results = self.sparqlData.query().convert()['results']['bindings']\n",
    "        # iterates over each resource and performs transformations\n",
    "        for result in results:\n",
    "            result = TransformationFactory().getTransformation(result, self.ptype)\n",
    "            if isinstance(result, list):\n",
    "                for triple in result:\n",
    "                    s = \"<%s>\" % (str(triple['subject']['value']))\n",
    "                    p = \"<%s>\" % (str(triple['predicate']['value']))\n",
    "                    if triple['object']['type'] == 'uri':\n",
    "                        o = \"<%s>\" % (str(triple['object']['value']))\n",
    "                    else:\n",
    "                        o = \"\\\"%s\\\"\" % (str(triple['object']['value']))\n",
    "                    self.streamOut.append(\"%s %s %s . \\n\" % (s, p, o))\n",
    "        with open(self.filename, \"w+\") as f:\n",
    "            f.writelines(self.streamOut)\n",
    "        #url = \"http://206.167.181.123:9999/blazegraph/namespace/results/sparql\"\n",
    "        #r = requests.post(url, params={'query': 'DELETE {?a ?b ?c} WHERE {?a ?b ?c}', 'Content-Type': 'text/turtle'})\n",
    "        #r = requests.post(url, files={'file': open(self.filename, \"rb\")}, params={'Content-Type: text/turtle'}) \n",
    "\n",
    "class CollectionData(Data):\n",
    "    def __init__(self, q, group, sparqlData, sparqlTerms, ptype):\n",
    "        super().__init__(q, group, sparqlData, sparqlTerms, ptype)\n",
    "\n",
    "class CommunityData(Data):\n",
    "    def __init__(self, q, group, sparqlData, sparqlTerms, ptype):\n",
    "        super().__init__(q, group, sparqlData, sparqlTerms, ptype)\n",
    "\n",
    "class ThesisData(Data):\n",
    "    def __init__(self, q, group, sparqlData, sparqlTerms, ptype):\n",
    "        super().__init__(q, group, sparqlData, sparqlTerms, ptype)             \n",
    "\n",
    "class GenericData(Data):\n",
    "    def __init__(self, q, group, sparqlData, sparqlTerms, ptype):\n",
    "        super().__init__(q, group, sparqlData, sparqlTerms, ptype)        \n",
    "\n",
    "class BatchData(Data):\n",
    "    def __init__(self, q, group, sparqlData, sparqlTerms, ptype):\n",
    "        super().__init__(q, group, sparqlData, sparqlTerms, ptype)\n",
    "\n",
    "class ContentData(Data):\n",
    "    def __init__(self, q, group, sparqlData, sparqlTerms, ptype):\n",
    "        super().__init__(q, group, sparqlData, sparqlTerms, ptype)\n",
    "        \n",
    "class CharacterizationData(Data):\n",
    "    def __init__(self, q, group, sparqlData, sparqlTerms, ptype):\n",
    "        super().__init__(q, group, sparqlData, sparqlTerms, ptype)\n",
    "\n",
    "class FedorafoxmlData(Data):\n",
    "    def __init__(self, q, group, sparqlData, sparqlTerms, ptype):\n",
    "        super().__init__(q, group, sparqlData, sparqlTerms, ptype)\n",
    "\n",
    "class Erastats1Data(Data):\n",
    "    def __init__(self, q, group, sparqlData, sparqlTerms, ptype):\n",
    "        super().__init__(q, group, sparqlData, sparqlTerms, ptype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QueryFactory():\n",
    "    @staticmethod\n",
    "    def getMigrationQuery(ptype, sparqlData):\n",
    "        \"\"\" returns a specified query object depending on the type passed in\"\"\"\n",
    "        if ptype == \"collection\": return Collection(sparqlData)\n",
    "        elif ptype == \"community\": return Community(sparqlData) \n",
    "        elif ptype == \"thesis\": return Thesis(sparqlData)\n",
    "        elif ptype == \"generic\": return Generic(sparqlData)\n",
    "        elif ptype == \"batch\": return Batch(sparqlData)\n",
    "        elif ptype == \"content\": return Content(sparqlData)\n",
    "        elif ptype == \"characterization\": return Characterization(sparqlData)\n",
    "        elif ptype == \"fedorafoxml\": return Fedorafoxml(sparqlData)\n",
    "        elif ptype == \"erastats1\": return Erastats1(sparqlData)\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataFactory():\n",
    "    @staticmethod\n",
    "    def getData(query, group, queryObject):\n",
    "        \"\"\" returns a specified query object depending on the type passed in\"\"\"\n",
    "        if queryObject.ptype == \"collection\": return CollectionData(query, group, queryObject.sparqlData, queryObject.sparqlTerms, queryObject) \n",
    "        elif queryObject.ptype == \"community\": return CommunityData(query, group, queryObject.sparqlData, queryObject.sparqlTerms, queryObject) \n",
    "        elif queryObject.ptype == \"thesis\": return ThesisData(query, group, queryObject.sparqlData, queryObject.sparqlTerms, queryObject)\n",
    "        elif queryObject.ptype == \"generic\": return GenericData(query, group, queryObject.sparqlData, queryObject.sparqlTerms, queryObject)\n",
    "        elif queryObject.ptype == \"batch\": return BatchData(query, group, queryObject.sparqlData, queryObject.sparqlTerms, queryObject)\n",
    "        elif queryObject.ptype == \"content\": return ContentData(query, group, queryObject.sparqlData, queryObject.sparqlTerms, queryObject)\n",
    "        elif queryObject.ptype == \"characterization\": return CharacterizationData(query, group, queryObject.sparqlData, queryObject.sparqlTerms, queryObject)\n",
    "        elif queryObject.ptype == \"fedorafoxml\": return FedorafoxmlData(query, group, queryObject.sparqlData, queryObject.sparqlTerms, queryObject)\n",
    "        elif queryObject.ptype == \"erastats1\": return Erastats1Data(query, group, queryObject.sparqlData, queryObject.sparqlTerms, queryObject)\n",
    "        \n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TransformationFactory():\n",
    "    @staticmethod\n",
    "    def getTransformation(triple, ptype):\n",
    "        function = re.sub(r'[0-9]+', '', triple['predicate']['value'].split('/')[-1].replace('#', '').replace('-', ''))\n",
    "        if function == \"rdfsyntaxnstype\": return Transformation().rdfsyntaxnstype(triple, ptype)\n",
    "        elif function == \"language\": return Transformation().language(triple, ptype)\n",
    "        elif function == \"type\": return Transformation().type(triple, ptype)\n",
    "        elif function ==  \"rights\": return Transformation().rights(triple, ptype)\n",
    "        elif function == \"license\": return Transformation().license(triple, ptype)\n",
    "        elif function == \"ontologyinstitution\": return Transformation().institution(triple, ptype)\n",
    "        else:\n",
    "            return [triple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection batch queries generated\n",
      "1 batch(es) of collection objects to be transformed\n",
      "EXCEPTION IN (<ipython-input-66-e7f504de14ab>, LINE 23 'future.result()'): too many values to unpack (expected 2)\n",
      "collection objects transformation completed\n",
      "community batch queries generated\n",
      "1 batch(es) of community objects to be transformed\n",
      "EXCEPTION IN (<ipython-input-66-e7f504de14ab>, LINE 23 'future.result()'): too many values to unpack (expected 2)\n",
      "community objects transformation completed\n",
      "generic batch queries generated\n",
      "248 batch(es) of generic objects to be transformed\n",
      "EXCEPTION IN (<ipython-input-66-e7f504de14ab>, LINE 23 'future.result()'): too many values to unpack (expected 2)\n",
      "EXCEPTION IN (<ipython-input-66-e7f504de14ab>, LINE 23 'future.result()'): too many values to unpack (expected 2)\n",
      "EXCEPTION IN (<ipython-input-66-e7f504de14ab>, LINE 23 'future.result()'): too many values to unpack (expected 2)\n",
      "EXCEPTION IN (<ipython-input-66-e7f504de14ab>, LINE 23 'future.result()'): too many values to unpack (expected 2)\n",
      "EXCEPTION IN (<ipython-input-66-e7f504de14ab>, LINE 23 'future.result()'): too many values to unpack (expected 2)\n",
      "EXCEPTION IN (<ipython-input-66-e7f504de14ab>, LINE 23 'future.result()'): too many values to unpack (expected 2)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-aa7afb95b669>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-e7f504de14ab>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mfuture_to_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparellelTransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueryObject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueryObject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture_to_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture_to_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    213\u001b[0m                             len(pending), len(fs)))\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
