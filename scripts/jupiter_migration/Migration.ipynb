{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  MAIN CONTROLLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from config import sparqlTerms, mig_ns, sparql_mig_test, sparql_mig_simple, sparql_mig_dev, vocabs, types\n",
    "from SPARQLWrapper import JSON, SPARQLWrapper\n",
    "from utilities import removeNS, PrintException, cleanOutputs\n",
    "import re, os, concurrent.futures, json, requests, time, datetime\n",
    "from rdflib import URIRef, Literal, Namespace, Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(datetime.datetime.fromtimestamp(time.time()).strftime('%H:%M:%S'))\n",
    "    sparqlData=sparql_mig_dev\n",
    "    #  Iterate over every type of object that needs to be migrated. \n",
    "    #  This is the first splitting of the data for migration.\n",
    "    cleanOutputs(types)\n",
    "    for objectType in types:\n",
    "        # a queryObject knows where it came from.\n",
    "        # a queryObject has been split into multiple groups\n",
    "        # only one group exists for community, and one for collection objects\n",
    "        # approximately a thousand queries each are minted for thesis and for generic objects\n",
    "        # these queries are based on the first folder in the fedora pair tree\n",
    "        queryObject = QueryFactory.getMigrationQuery(objectType, sparqlData)\n",
    "        queryObject.generateQueries()\n",
    "        print('%s queries generated' % (objectType))\n",
    "        print('%i queries of %s objects to be transformed' % (len(queryObject.queries), objectType))\n",
    "        i = 0\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "            \n",
    "            future_to_result = {executor.submit(parellelTransform, queryObject, group): group for group in queryObject.queries.keys()}\n",
    "            for future in concurrent.futures.as_completed(future_to_result):\n",
    "                result = future_to_result[future]\n",
    "                try:\n",
    "                    i = i + 1\n",
    "                    future.result()\n",
    "                    print(\"%i of %i %s queries transformed\" % (i, len(queryObject.queries), objectType) )\n",
    "                except Exception:\n",
    "                    PrintException()\n",
    "        #queryObject.postResults()\n",
    "        print(\"%s objects transformation completed\" % (objectType) )\n",
    "        del queryObject\n",
    "    print(datetime.datetime.fromtimestamp(time.time()).strftime('%H:%M:%S'))\n",
    "\n",
    "def parellelTransform(queryObject, group):\n",
    "    DTO = Data(queryObject.queries[group], group, queryObject.sparqlData, sparqlTerms, queryObject) # query, group, object\n",
    "    DTO.transformData()\n",
    "    DTO.resultsToTriplestore()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TRANSFORMATIONS\n",
    "#### functions for handling data passed over by the data object. Takes a triple, detects what kind of action needs to be taken based on the predicate, sends it to the appropriate function for transformations, then returns it back to the data handler to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Transformation():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.output = []\n",
    "       \n",
    "    ############################################################################\n",
    "    ######################## transformation on dcterms:language ################\n",
    "    ############################################################################\n",
    "\n",
    "    def language(self, triple, objectType):\n",
    "        # normalize values and convert to URI (consult the \"vocabs\" variable from the config file (this folder))\n",
    "        for vocab in vocabs[\"language\"]:\n",
    "            # mint a new triple with the mapped type\n",
    "            if triple['object']['value'] in  vocab[\"mapping\"]:\n",
    "                self.output.append(\n",
    "                    {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': triple['predicate']['value'], # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value': vocab[\"uri\"], # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        } \n",
    "                    ) \n",
    "        return self.output\n",
    "\n",
    "\n",
    "    ############################################################################\n",
    "    ######################## transformation on dc:rights #######################\n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "    def rights(self, triple, objectType):\n",
    "        #### \n",
    "        # several different license values need to be coerced into one common value, this needs to be confirmed with leah before it is written\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "\n",
    "    ############################################################################\n",
    "    ######################## transformation on dc:license ######################\n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "    def license(self, triple, objectType):\n",
    "        #### \n",
    "        \n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "    \n",
    "    ############################################################################\n",
    "    ######################## transformation on acl:visibilityAfterEmbargo ######################\n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "    def aclvisibilityAfterEmbargo(self, triple, objectType):\n",
    "        if (\"open\" in triple['object']['value']) or (\"open access\" in triple['object']['value']):\n",
    "            triple['object']['value'] = \"http://terms.library.ualberta.ca/public\"\n",
    "            triple['object']['type'] = 'uri'\n",
    "            self.output.append(triple)\n",
    "            return self.output            \n",
    "        elif \"university_of_alberta\" in triple['object']['value']:\n",
    "            triple['object']['value'] = \"http://terms.library.ualberta.ca/authenticated\"\n",
    "            triple['object']['type'] = 'uri'\n",
    "            self.output.append(triple)\n",
    "            return self.output\n",
    "    \n",
    "    ############################################################################\n",
    "    ######################## transformation on ual:institution #################\n",
    "    ############################################################################\n",
    "\n",
    "    def institution(self, triple, objectType):\n",
    "        self.output.append(\n",
    "            {\n",
    "            'subject': {\n",
    "                'value': triple['subject']['value'], \n",
    "                'type': 'uri'\n",
    "            }, \n",
    "            'predicate': {\n",
    "                'value': triple['predicate']['value'], \n",
    "                'type': 'uri'\n",
    "            }, \n",
    "            'object': {\n",
    "                'value': 'http://id.loc.gov/authorities/names/n79058482', \n",
    "                'type': 'uri'\n",
    "            }\n",
    "        }\n",
    "        )\n",
    "        return self.output\n",
    " \n",
    "\n",
    "    ############################################################################\n",
    "    ######################## transformation on dcterms:license #################\n",
    "    ############################################################################\n",
    "\n",
    "    \n",
    "    def license(self, triple, objectType):\n",
    "        #### \n",
    "        # convert licenses from text to URI (use vocabs variable, some coersion will be necessary)\n",
    "        if \"I am required to use/link to a publisher's license\" in triple['object']['value']:\n",
    "            return None\n",
    "        else:\n",
    "            for vocab in vocabs[\"license\"]:\n",
    "                if triple['object']['value'] in vocab[\"mapping\"]:\n",
    "                    self.output.append(\n",
    "                        {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': triple['predicate']['value'], # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value': vocab[\"uri\"], # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        }\n",
    "                    )\n",
    "            if len(self.output)>0:\n",
    "                return self.output\n",
    "            else:\n",
    "                self.output.append(\n",
    "                    {\n",
    "                        'subject': {\n",
    "                            'value': triple['subject']['value'], # the subject of the triple\n",
    "                            'type': 'uri'\n",
    "                        }, \n",
    "                        'predicate': {\n",
    "                            'value': \"http://purl.org/dc/elements/1.1/rights\", # the predicate of the triple\n",
    "                            'type': 'uri'\n",
    "                        }, \n",
    "                        'object': {\n",
    "                            'value': triple['object']['value'], # mapped uri\n",
    "                            'type': 'literal'\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "                return self.output\n",
    "    \n",
    "    ############################################################################\n",
    "    ######################## transformation on dcterms:type ####################\n",
    "    ############################################################################\n",
    "    \n",
    "    def type(self, triple, objectType):\n",
    "        if objectType == 'generic':\n",
    "            for vocab in vocabs[\"type\"]:\n",
    "                # mint a new triple with the mapped type\n",
    "                if triple['object']['value'] in vocab[\"mapping\"]:\n",
    "                    self.output.append(\n",
    "                        {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': triple['predicate']['value'], # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value': vocab[\"uri\"], # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        }\n",
    "                    )\n",
    "     \n",
    "            else:\n",
    "                pass\n",
    "        elif (objectType == 'community') or (objectType == 'collection'):\n",
    "            self.output.append(triple)\n",
    "        \n",
    "        return self.output\n",
    "        \n",
    "    def modelsmemberOf(self, triple, objectType):\n",
    "        if \"http\" not in triple['object']['value']:\n",
    "            value = triple['object']['value']\n",
    "            triple['object']['value'] = \"http://gillingham.library.ualberta.ca:8080/fedora/rest/prod/%s/%s/%s/%s/%s\" % (value[0:2], value[2:4], value[4:6], value[6:8], value)\n",
    "            triple['object']['type'] = 'uri'\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "\n",
    "    def modelshasMember(self, triple, objectType):\n",
    "        if \"http\" not in triple['object']['value']:\n",
    "            value = triple['object']['value']\n",
    "            triple['object']['value'] = \"http://gillingham.library.ualberta.ca:8080/fedora/rest/prod/%s/%s/%s/%s/%s\" % (value[0:2], value[2:4], value[4:6], value[6:8], value)\n",
    "            triple['object']['type'] = 'uri'\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "    \n",
    "    def accessRights(self, triple, objectType):\n",
    "        if \"http://projecthydra.org/ns/auth/group#public\" in triple['object']['value']:\n",
    "            triple['object']['value'] = \"http://terms.library.ualberta.ca/public\"\n",
    "            triple['object']['type'] = 'uri'\n",
    "            self.output.append(triple)\n",
    "            return self.output            \n",
    "        elif (\"http://projecthydra.org/ns/auth/group#university_of_alberta\" in triple['object']['value']) or (\"http://projecthydra.org/ns/auth/group#registered\" in triple['object']['value']):\n",
    "            triple['object']['value'] = \"http://terms.library.ualberta.ca/authenticated\"\n",
    "            triple['object']['type'] = 'uri'\n",
    "            self.output.append(triple)\n",
    "            return self.output \n",
    "        else:\n",
    "            triple['object']['value'] = \"http://terms.library.ualberta.ca/private\"\n",
    "            triple['object']['type'] = 'uri'\n",
    "            self.output.append(triple)\n",
    "            return self.output\n",
    "    \n",
    "    def available(self, triple, objectType):\n",
    "        self.output.append(triple)\n",
    "        self.output.append(\n",
    "                        {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': \"http://purl.org/dc/terms/accessRights\", # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value':\"http://terms.library.ualberta.ca/public\", # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        }        \n",
    "        )\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  QUERY BUILDER\n",
    "##### Pulls current mappings from triplestore, dynamically builds queries in managable sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Query(object):\n",
    "    \"\"\" Query objects are dynamically generated, and contain SPARQL CONSTRUCT queries with input from the jupiter application profile \"\"\"\n",
    "    def __init__(self, objectType, sparqlData, sparqlTerms=sparqlTerms):\n",
    "        self.mapping = []\n",
    "        self.sparqlTerms = SPARQLWrapper(sparqlTerms)  # doesn't need to change (the terms store doesn't change)\n",
    "        self.sparqlData = SPARQLWrapper(sparqlData)  # sets the triple store from which to get data (simple, test, or dev)\n",
    "        self.sparqlResults = SPARQLWrapper(\"http://206.167.181.123:9999/blazegraph/namespace/results/sparql\")\n",
    "        self.sparqlTerms.setMethod(\"POST\")\n",
    "        self.sparqlData.setMethod(\"POST\")\n",
    "        self.sparqlResults.setMethod(\"POST\")\n",
    "        self.queries = {}\n",
    "        self.splitBy = {}\n",
    "        self.prefixes = \"\"\n",
    "        self.filename = \"\"\n",
    "        for ns in mig_ns:\n",
    "            self.prefixes = self.prefixes + \" PREFIX %s: <%s> \" % (ns['prefix'], ns['uri'])\n",
    "        self.getMappings()\n",
    "        \n",
    "\n",
    "    \n",
    "    def postResults(self):\n",
    "        directory = 'results/%s' % (self.objectType)\n",
    "        for (dirpath, dirnames, filenames) in os.walk(directory):\n",
    "            for filename in filenames:\n",
    "                with open(os.path.join(dirpath, filename), 'rb') as f:\n",
    "                    query = \"INSERT DATA {%s}\" % (f.read())\n",
    "                    self.sparqlResults.setReturnFormat(JSON)\n",
    "                    self.sparqlResults.setQuery(query)\n",
    "                    self.sparqlResults.query()                        \n",
    "                \n",
    "    \n",
    "    def getMappings(self):\n",
    "        if (self.objectType == 'collection') or (self.objectType == 'community') or (self.objectType == 'generic') or (self.objectType ==  'thesis'):\n",
    "            query = \"prefix ual: <http://terms.library.ualberta.ca/>SELECT * WHERE {GRAPH ual:%s {?newProperty ual:backwardCompatibleWith ?oldProperty} }\" % (self.objectType)\n",
    "            self.sparqlTerms.setReturnFormat(JSON)\n",
    "            self.sparqlTerms.setQuery(query)\n",
    "            results = self.sparqlTerms.query().convert()\n",
    "            for result in results['results']['bindings']:\n",
    "                self.mapping.append((result['newProperty']['value'], result['oldProperty']['value']))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def getSplitBy(self):\n",
    "        # base query only needs 3 prefixes appended to the \"select\" statement defined by the object\n",
    "        query = \"prefix dcterm: <http://purl.org/dc/terms/> prefix info: <info:fedora/fedora-system:def/model#> prefix ual: <http://terms.library.ualberta.ca/> %s\" % (self.select)\n",
    "        self.sparqlData.setReturnFormat(JSON)\n",
    "        self.sparqlData.setQuery(query)\n",
    "        results =  self.sparqlData.query().convert()\n",
    "        # iterate over query results\n",
    "        for result in results['results']['bindings']:\n",
    "            # the group is the two folders at the base of the pair tree, concatenated by an underscore\n",
    "            group = result['resource']['value'].split('/')[6]\n",
    "            # assign that parameter by which you want to search to that group\n",
    "            self.splitBy[group] = \"/\".join( result['resource']['value'].split('/')[:7] )# the stem of the resource [0] and the group number by which to save [1] (this is the first digit in the pair tree)\n",
    "            \n",
    "\n",
    "    def generateQueries(self):\n",
    "        pass\n",
    "    \n",
    "    def writeQueries(self):\n",
    "        filename = \"cache/%s.json\" % (self.objectType)\n",
    "        with open(filename, 'w+') as f:\n",
    "            json.dump([self.queries], f, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "               \n",
    "class Collection(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.objectType = 'collection'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Collection\"\n",
    "        self.where = [\"WHERE { ?resource info:hasModel 'Collection'^^xsd:string . OPTIONAL { ?resource ualids:is_community 'false'^^xsd:boolean } . OPTIONAL { ?resource ualid:is_community 'false'^^xsd:boolean } . OPTIONAL { ?resource ual:is_community 'false'^^xsd:boolean }\"]\n",
    "        self.select = None\n",
    "        super().__init__(self.objectType, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        for where in self.where:\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (str(?%s)!='') }\" % (where, pair[1], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')), re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "            self.queries['collection'] = \"%s %s } %s }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries\n",
    "\n",
    "class Community(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.objectType = 'community'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Object; rdf:type ual:Community\"\n",
    "        self.where = [\"WHERE { ?resource info:hasModel 'Collection'^^xsd:string ; OPTIONAL { ?resource ualids:is_community 'true'^^xsd:boolean } . OPTIONAL { ?resource ualid:is_community 'true'^^xsd:boolean } . OPTIONAL { ?resource ual:is_community 'true'^^xsd:boolean }\"]\n",
    "        self.select = None\n",
    "        super().__init__(self.objectType, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        for where in self.where:\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (str(?%s)!='') }\" % (where, pair[1], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')), re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "            self.queries['community'] = \"%s %s } %s }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries()\n",
    "\n",
    "class Generic(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.objectType = 'generic'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; dcterm:available ?available ; dcterm:accessRights ?visibility; rdf:type works:Work; rdf:type pcdm:Object ; bibo:owner ?owner ; acl:embargoHistory ?history ; acl:visibilityAfterEmbargo ?visAfter\"\n",
    "        self.where = []\n",
    "        self.select = \"SELECT distinct ?resource WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type ?type . filter(str(?type) != 'Thesis'^^xsd:string) }\"\n",
    "        super().__init__(self.objectType, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        query = \"%s %s\" % (self.prefixes, self.select)\n",
    "        for group in self.splitBy.keys():\n",
    "            where = \"WHERE {  ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type ?type . filter(str(?type) != 'Thesis'^^xsd:string) . FILTER (contains(str(?resource), '%s'))\" % (self.splitBy[group])\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (str(?%s)!='') }\" % (where, pair[1], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')), re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "            self.queries[group] =  \"%s %s } %s . OPTIONAL {?permission webacl:accessTo ?resource ; webacl:mode webacl:Read ; webacl:agent ?visibility } . OPTIONAL {?permission webacl:accessTo ?resource ; webacl:mode webacl:Write ; webacl:agent ?owner } . OPTIONAL {?resource acl:hasEmbargo ?embargo . OPTIONAL {?embargo acl:embargoReleaseDate ?available } . OPTIONAL {?embargo acl:embargoHistory ?history } . OPTIONAL {?embargo acl:visibilityAfterEmbargo ?visAfter } } }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries()\n",
    "\n",
    "\n",
    "class Thesis(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.objectType = 'thesis'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; dcterm:available ?available ; dcterm:accessRights ?visibility; rdf:type works:Work ; rdf:type pcdm:Object ; rdf:type bibo:Thesis; bibo:owner ?owner ; acl:embargoHistory ?history ; acl:visibilityAfterEmbargo ?visAfter\"\n",
    "        self.where = []\n",
    "        self.select = \"SELECT distinct ?resource WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type 'Thesis'^^xsd:string }\"\n",
    "        super().__init__(self.objectType, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()        \n",
    "        query = \"%s %s\" % (self.prefixes, self.select)\n",
    "        for group in self.splitBy.keys():\n",
    "            where = \"WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type 'Thesis'^^xsd:string . FILTER (contains(str(?resource), '%s'))\" % (self.splitBy[group])\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (str(?%s)!='') } \" % (where, pair[1], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')), re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "            self.queries[group] =  \"%s %s } %s . OPTIONAL {?permission webacl:accessTo ?resource ; webacl:mode webacl:Read ; webacl:agent ?visibility } . OPTIONAL {?permission webacl:accessTo ?resource ; webacl:mode webacl:Write ; webacl:agent ?owner } . OPTIONAL {?resource acl:hasEmbargo ?embargo . OPTIONAL {?embargo acl:embargoReleaseDate ?available } . OPTIONAL {?embargo acl:embargoHistory ?history } . OPTIONAL {?embargo acl:visibilityAfterEmbargo ?visAfter } } }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries()\n",
    "\n",
    "\n",
    "class File(Query):\n",
    "    def __init__(self, sparqlData, objectType, filterType):\n",
    "        self.rdfType = \"<http://www.w3.org/ns/ldp#NonRDFSource>\"\n",
    "        self.pcdmType = \"pcdm:File\"\n",
    "        self.construct = \"CONSTRUCT {?file rdf:type %s; rdf:type %s; pcdm:fileOf ?fileset ; iana:describedby ?fixty ; iana:describedby ?fcr ; fedora:hasParent ?fileset ; ?predicate ?object }\" % (self.rdfType, self.pcdmType)\n",
    "        self.where = \"WHERE { ?resource rdf:type %s . FILTER ( strEnds(str(?resource), '%s') && \" % (self.rdfType, self.filterType)\n",
    "        self.select = \"SELECT distinct ?resource WHERE  {?resource rdf:type %s . FILTER ( strEnds(str(?resource), '%s') ) }\" % (self.rdfType, self.filterType)\n",
    "        super().__init__(self.objectType, self.sparqlData)\n",
    "        \n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        for group in self.splitBy.keys():\n",
    "            self.queries[group] = \"%s %s %s strStarts(str(?resource), '%s') ) . ?resource ?predicate ?object . FILTER ( !contains(str(?predicate), 'http://www.iana.org/assignments/relation/') && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasFixityService')  && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasParent') && str(?object)!='' )  . BIND(URI(CONCAT(str(?resource), '/file')) AS ?file)  . BIND(URI(CONCAT(str(?resource), '/fileset')) AS ?fileset) . BIND(URI(CONCAT(str(?resource), '/file/fcr:fixity')) AS ?fixity)  . BIND(URI(CONCAT(str(?resource), '/file/fcr:metadata')) AS ?fcr)}\" % (self.prefixes, self.construct, self.where, self.splitBy[group])\n",
    "        self.writeQueries()    \n",
    "\n",
    "\n",
    "class Fileset(Query):\n",
    "    def __init__(self, sparqlData, objectType, filterType):\n",
    "        self.pcdmType = \"works:Fileset\"\n",
    "        self.rdfType = \"<http://fedora.info/definitions/v4/repository#NonRdfSourceDescription>\"\n",
    "        self.construct = \"CONSTRUCT { ?parent pcdm:hasRelatedObject ?relatedObject . ?fileset rdf:type fedora:Container ; rdf:type fedora:Resource ; rdf:type pcdm:Object ; rdf:type works:FileSet; rdf:type <http://www.w3.org/ns/ldp#Container> ; rdf:type <http://www.w3.org/ns/ldp#RDFSource> ; pcdm:hasFile ?file ; pcdm:isMemberOf ?relatedObject ; fedora:hasParent ?relatedObject . ?relatedObject pcdm:relatedObjectOf ?parent ; rdf:type ual:%s ; rdf:type fedora:Container ; rdf:type fedora:Resource ; rdf:type pcdm:Object ; rdf:type works:Work ; rdf:type <http://www.w3.org/ns/ldp#Container> ; rdf:type <http://www.w3.org/ns/ldp#RDFSource> ; pcdm:hasMember ?fileset ; fedora:hasParent ?parent ; ?predicate ?object } \" % (self.filterType)\n",
    "        self.where = \"WHERE { ?resource rdf:type %s . FILTER ( strEnds(str(?resource), '%s/fcr:metadata') && \" % (self.rdfType, self.filterType)\n",
    "        self.select = \"SELECT distinct ?resource WHERE {?resource rdf:type %s . FILTER ( strEnds(str(?resource), '%s/fcr:metadata') ) }\" % (self.rdfType, self.filterType)\n",
    "        super().__init__(self.objectType, self.sparqlData)\n",
    "        \n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        for group in self.splitBy.keys():\n",
    "            self.queries[group] = \"%s %s %s strStarts(str(?resource), '%s')) . ?resource ?predicate ?object FILTER ( !contains(str(?predicate), 'http://www.iana.org/assignments/relation/') && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasFixityService') && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasParent') && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasVersions') && str(?object)!='' )  . BIND(URI(REPLACE(STR(?resource), '/%s/fcr:metadata', '/fileset')) AS ?fileset) . BIND(URI(REPLACE(STR(?resource), '/%s/fcr:metadata', '/file')) AS ?file)  . BIND(URI(REPLACE(STR(?resource), '/%s/fcr:metadata', '')) AS ?parent) . BIND(URI(REPLACE(STR(?resource), '/fcr:metadata', '/relatedObject')) AS ?relatedObject) }\" % (self.prefixes, self.construct, self.where, self.splitBy[group], self.filterType, self.filterType, self.filterType)\n",
    "        self.writeQueries()     \n",
    "\n",
    "\n",
    "class era1statsFile(File):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'era1statsFile'        \n",
    "        self.filterType = \"era1stats\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "\n",
    "        \n",
    "class era1statsFileset(Fileset):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'era1statsFileset'        \n",
    "        self.filterType = \"era1stats\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)  \n",
    "        \n",
    "\n",
    "class fedora3foxmlFile(File):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'fedora3foxmlFile'        \n",
    "        self.filterType = \"fedora3foxml\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        \n",
    "\n",
    "class fedora3foxmlFileset(Fileset):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'fedora3foxmlFileset'        \n",
    "        self.filterType = \"fedora3foxml\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        \n",
    "\n",
    "class contentFile(File):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'contentFile'\n",
    "        self.filterType = \"content\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        self.construct = \"CONSTRUCT { ?file rdf:type ldp:NonRDFSource ; rdf:type fedora:Binary ; rdf:type fedora:Resource ; rdf:type pcdm:File; pcdm:fileOf ?fileset; iana:describedby ?fcr ; ?predicate ?object }\"\n",
    "\n",
    "        \n",
    "class contentFileset(Fileset):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'contentFileset'\n",
    "        self.filterType = \"content\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        self.construct = \"CONSTRUCT { ?fileset rdf:type fedora:Container ; rdf:type fedora:Resource ; rdf:type pcdm:Object ; rdf:type works:FileSet; rdf:type ldp:Container ; rdf:type ldp:RDFSource ; pcdm:hasFile ?file ; pcdm:memberOf ?parent ; ?predicate ?object }\"\n",
    "        \n",
    "        \n",
    "class characterizationFile(File):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'characterizationFile'\n",
    "        self.filterType = \"characterization\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        self.construct = \"CONSTRUCT { ?file rdf:type ldp:NonRDFSource ; rdf:type fedora:Binary ; rdf:type fedora:Resource ; rdf:type pcdm:File; pcdm:fileOf ?fileset; iana:describedby ?fcr ; ?predicate ?object }\"\n",
    "\n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        for group in self.splitBy.keys():\n",
    "            self.queries[group] = \"%s %s %s strStarts(str(?resource), '%s') ) . ?resource ?predicate ?object . FILTER ( !contains(str(?predicate), 'http://www.iana.org/assignments/relation/') && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasFixityService')  && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasParent') && str(?object)!='' )  . BIND(URI(CONCAT(str(?resource), '/file')) AS ?file)  . BIND(URI(REPLACE(str(?resource), '/characterization', '/fileset')) AS ?fileset) . BIND(URI(CONCAT(str(?resource), '/file/fcr:fixity')) AS ?fixity)  . BIND(URI(CONCAT(str(?resource), '/file/fcr:metadata')) AS ?fcr)}\" % (self.prefixes, self.construct, self.where, self.splitBy[group])\n",
    "        self.writeQueries() \n",
    "    \n",
    "class characterizationFileset(Fileset):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'characterizationFileset'\n",
    "        self.filterType = \"characterization\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        self.construct = \"CONSTRUCT { ?fileset rdf:type %s; rdf:type %s; rdf:type ual:fits ; pcdm:hasFile ?file ; pcdm:memberOf ?parent ; iana:describes ?file ; ?predicate ?object }\" % (self.rdfType, self.pcdmType)      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  DATA TRANSPORT OBJECTS\n",
    "##### Runs a query, sends data to get transformed, saves data to appropriate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    def __init__(self, query, group, sparqlData, sparqlTerms, queryObject):\n",
    "        self.q = query\n",
    "        self.prefixes = queryObject.prefixes\n",
    "        self.group = group\n",
    "        self.sparqlData = sparqlData\n",
    "        self.sparqlTerms = sparqlTerms\n",
    "        self.output = []\n",
    "        self.graph = Graph()\n",
    "        self.objectType = queryObject.objectType\n",
    "        self.directory = \"results/%s/\" % (self.objectType)\n",
    "        self.filename = \"results/%s/%s.nt\" % (self.objectType, group)\n",
    "        if not os.path.exists(self.directory):\n",
    "            os.makedirs(self.directory)\n",
    "\n",
    "    def transformData(self):\n",
    "        self.sparqlData.setReturnFormat(JSON)\n",
    "        self.sparqlData.setQuery(self.q)\n",
    "        # queries a batch of resources from this particular \"group\"\n",
    "        results = self.sparqlData.query().convert()['results']['bindings']\n",
    "        # iterates over each resource and performs transformations\n",
    "        for result in results:\n",
    "            result = TransformationFactory().getTransformation(result, self.objectType)\n",
    "            if isinstance(result, list):\n",
    "                for triple in result:\n",
    "                    s = URIRef(triple['subject']['value'])\n",
    "                    p = URIRef(triple['predicate']['value'])\n",
    "                    if triple['object']['type'] == 'uri':\n",
    "                        o = URIRef(triple['object']['value'])\n",
    "                    else:\n",
    "                        o = Literal(triple['object']['value'])\n",
    "                    self.graph.add((s, p, o))\n",
    "        self.graph.serialize(destination=self.filename, format='nt')\n",
    "        \n",
    "    def resultsToTriplestore(self):\n",
    "        url = 'http://206.167.181.123:9999/blazegraph/namespace/results/sparql'\n",
    "        headers = {'Content-Type': 'text/turtle'}\n",
    "        r = requests.post(url, data=self.graph.serialize(format='nt'), headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QueryFactory():\n",
    "    @staticmethod\n",
    "    def getMigrationQuery(objectType, sparqlData):\n",
    "        \"\"\" returns a specified query object depending on the type passed in\"\"\"\n",
    "        if objectType == \"collection\": return Collection(sparqlData)\n",
    "        elif objectType == \"community\": return Community(sparqlData) \n",
    "        elif objectType == \"thesis\": return Thesis(sparqlData)\n",
    "        elif objectType == \"generic\": return Generic(sparqlData)\n",
    "        elif objectType == \"era1statsFile\": return era1statsFile(sparqlData)\n",
    "        elif objectType == \"era1statsFileset\": return era1statsFileset(sparqlData) \n",
    "        elif objectType == \"fedora3foxmlFile\": return fedora3foxmlFile(sparqlData)\n",
    "        elif objectType == \"fedora3foxmlFileset\": return fedora3foxmlFileset(sparqlData) \n",
    "        elif objectType == \"contentFile\": return contentFile(sparqlData)\n",
    "        elif objectType == \"contentFileset\": return contentFileset(sparqlData) \n",
    "        elif objectType == \"characterizationFile\": return characterizationFile(sparqlData)\n",
    "        elif objectType == \"characterizationFileset\": return characterizationFileset(sparqlData)\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TransformationFactory():\n",
    "    @staticmethod\n",
    "    def getTransformation(triple, objectType):\n",
    "        function = re.sub(r'[0-9]+', '', triple['predicate']['value'].split('/')[-1].replace('#', '').replace('-', ''))      \n",
    "        if function ==  \"accessRights\": return Transformation().accessRights(triple, objectType)\n",
    "        elif function ==  \"modelsmemberOf\": return Transformation().modelsmemberOf(triple, objectType)\n",
    "        elif function ==  \"modelshasMember\": return Transformation().modelshasMember(triple, objectType)\n",
    "        elif function == \"language\": return Transformation().language(triple, objectType)\n",
    "        elif function == \"type\": return Transformation().type(triple, objectType)\n",
    "        elif function ==  \"rights\": return Transformation().rights(triple, objectType)\n",
    "        elif function == \"license\": return Transformation().license(triple, objectType)\n",
    "        elif function == \"ontologyinstitution\": return Transformation().institution(triple, objectType)\n",
    "        elif function == \"available\": return Transformation().available(triple, objectType)\n",
    "        elif function == \"aclvisibilityAfterEmbargo\": return Transformation().aclvisibilityAfterEmbargo(triple, objectType)\n",
    "        else:\n",
    "            return [triple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:40:48\n",
      "collection queries generated\n",
      "1 queries of collection objects to be transformed\n",
      "1 of 1 collection queries transformed\n",
      "collection objects transformation completed\n",
      "community queries generated\n",
      "1 queries of community objects to be transformed\n",
      "1 of 1 community queries transformed\n",
      "community objects transformation completed\n",
      "generic queries generated\n",
      "332 queries of generic objects to be transformed\n",
      "1 of 332 generic queries transformed\n",
      "2 of 332 generic queries transformed\n",
      "3 of 332 generic queries transformed\n",
      "4 of 332 generic queries transformed\n",
      "5 of 332 generic queries transformed\n",
      "6 of 332 generic queries transformed\n",
      "7 of 332 generic queries transformed\n",
      "8 of 332 generic queries transformed\n",
      "9 of 332 generic queries transformed\n",
      "10 of 332 generic queries transformed\n",
      "11 of 332 generic queries transformed\n",
      "12 of 332 generic queries transformed\n",
      "13 of 332 generic queries transformed\n",
      "14 of 332 generic queries transformed\n",
      "15 of 332 generic queries transformed\n",
      "16 of 332 generic queries transformed\n",
      "17 of 332 generic queries transformed\n",
      "18 of 332 generic queries transformed\n",
      "19 of 332 generic queries transformed\n",
      "20 of 332 generic queries transformed\n",
      "21 of 332 generic queries transformed\n",
      "22 of 332 generic queries transformed\n",
      "23 of 332 generic queries transformed\n",
      "24 of 332 generic queries transformed\n",
      "25 of 332 generic queries transformed\n",
      "26 of 332 generic queries transformed\n",
      "27 of 332 generic queries transformed\n",
      "28 of 332 generic queries transformed\n",
      "29 of 332 generic queries transformed\n",
      "30 of 332 generic queries transformed\n",
      "31 of 332 generic queries transformed\n",
      "32 of 332 generic queries transformed\n",
      "33 of 332 generic queries transformed\n",
      "34 of 332 generic queries transformed\n",
      "35 of 332 generic queries transformed\n",
      "36 of 332 generic queries transformed\n",
      "37 of 332 generic queries transformed\n",
      "38 of 332 generic queries transformed\n",
      "39 of 332 generic queries transformed\n",
      "40 of 332 generic queries transformed\n",
      "41 of 332 generic queries transformed\n",
      "42 of 332 generic queries transformed\n",
      "43 of 332 generic queries transformed\n",
      "44 of 332 generic queries transformed\n",
      "45 of 332 generic queries transformed\n",
      "46 of 332 generic queries transformed\n",
      "47 of 332 generic queries transformed\n",
      "48 of 332 generic queries transformed\n",
      "49 of 332 generic queries transformed\n",
      "50 of 332 generic queries transformed\n",
      "51 of 332 generic queries transformed\n",
      "52 of 332 generic queries transformed\n",
      "53 of 332 generic queries transformed\n",
      "54 of 332 generic queries transformed\n",
      "55 of 332 generic queries transformed\n",
      "56 of 332 generic queries transformed\n",
      "57 of 332 generic queries transformed\n",
      "58 of 332 generic queries transformed\n",
      "59 of 332 generic queries transformed\n",
      "60 of 332 generic queries transformed\n",
      "61 of 332 generic queries transformed\n",
      "62 of 332 generic queries transformed\n",
      "63 of 332 generic queries transformed\n",
      "64 of 332 generic queries transformed\n",
      "65 of 332 generic queries transformed\n",
      "66 of 332 generic queries transformed\n",
      "67 of 332 generic queries transformed\n",
      "68 of 332 generic queries transformed\n",
      "69 of 332 generic queries transformed\n",
      "70 of 332 generic queries transformed\n",
      "71 of 332 generic queries transformed\n",
      "72 of 332 generic queries transformed\n",
      "73 of 332 generic queries transformed\n",
      "74 of 332 generic queries transformed\n",
      "75 of 332 generic queries transformed\n",
      "76 of 332 generic queries transformed\n",
      "77 of 332 generic queries transformed\n",
      "78 of 332 generic queries transformed\n",
      "79 of 332 generic queries transformed\n",
      "80 of 332 generic queries transformed\n",
      "81 of 332 generic queries transformed\n",
      "82 of 332 generic queries transformed\n",
      "83 of 332 generic queries transformed\n",
      "84 of 332 generic queries transformed\n",
      "85 of 332 generic queries transformed\n",
      "86 of 332 generic queries transformed\n",
      "87 of 332 generic queries transformed\n",
      "88 of 332 generic queries transformed\n",
      "89 of 332 generic queries transformed\n",
      "90 of 332 generic queries transformed\n",
      "91 of 332 generic queries transformed\n",
      "92 of 332 generic queries transformed\n",
      "93 of 332 generic queries transformed\n",
      "94 of 332 generic queries transformed\n",
      "95 of 332 generic queries transformed\n",
      "96 of 332 generic queries transformed\n",
      "97 of 332 generic queries transformed\n",
      "98 of 332 generic queries transformed\n",
      "99 of 332 generic queries transformed\n",
      "100 of 332 generic queries transformed\n",
      "101 of 332 generic queries transformed\n",
      "102 of 332 generic queries transformed\n",
      "103 of 332 generic queries transformed\n",
      "104 of 332 generic queries transformed\n",
      "105 of 332 generic queries transformed\n",
      "106 of 332 generic queries transformed\n",
      "107 of 332 generic queries transformed\n",
      "108 of 332 generic queries transformed\n",
      "109 of 332 generic queries transformed\n",
      "110 of 332 generic queries transformed\n",
      "111 of 332 generic queries transformed\n",
      "112 of 332 generic queries transformed\n",
      "113 of 332 generic queries transformed\n",
      "114 of 332 generic queries transformed\n",
      "115 of 332 generic queries transformed\n",
      "116 of 332 generic queries transformed\n",
      "117 of 332 generic queries transformed\n",
      "118 of 332 generic queries transformed\n",
      "119 of 332 generic queries transformed\n",
      "120 of 332 generic queries transformed\n",
      "121 of 332 generic queries transformed\n",
      "122 of 332 generic queries transformed\n",
      "123 of 332 generic queries transformed\n",
      "124 of 332 generic queries transformed\n",
      "125 of 332 generic queries transformed\n",
      "126 of 332 generic queries transformed\n",
      "127 of 332 generic queries transformed\n",
      "128 of 332 generic queries transformed\n",
      "129 of 332 generic queries transformed\n",
      "130 of 332 generic queries transformed\n",
      "131 of 332 generic queries transformed\n",
      "132 of 332 generic queries transformed\n",
      "133 of 332 generic queries transformed\n",
      "134 of 332 generic queries transformed\n",
      "135 of 332 generic queries transformed\n",
      "136 of 332 generic queries transformed\n",
      "137 of 332 generic queries transformed\n",
      "138 of 332 generic queries transformed\n",
      "139 of 332 generic queries transformed\n",
      "140 of 332 generic queries transformed\n",
      "141 of 332 generic queries transformed\n",
      "142 of 332 generic queries transformed\n",
      "143 of 332 generic queries transformed\n",
      "144 of 332 generic queries transformed\n",
      "145 of 332 generic queries transformed\n",
      "146 of 332 generic queries transformed\n",
      "147 of 332 generic queries transformed\n",
      "148 of 332 generic queries transformed\n",
      "149 of 332 generic queries transformed\n",
      "150 of 332 generic queries transformed\n",
      "151 of 332 generic queries transformed\n",
      "152 of 332 generic queries transformed\n",
      "153 of 332 generic queries transformed\n",
      "154 of 332 generic queries transformed\n",
      "155 of 332 generic queries transformed\n",
      "156 of 332 generic queries transformed\n",
      "157 of 332 generic queries transformed\n",
      "158 of 332 generic queries transformed\n",
      "159 of 332 generic queries transformed\n",
      "160 of 332 generic queries transformed\n",
      "161 of 332 generic queries transformed\n",
      "162 of 332 generic queries transformed\n",
      "163 of 332 generic queries transformed\n",
      "164 of 332 generic queries transformed\n",
      "165 of 332 generic queries transformed\n",
      "166 of 332 generic queries transformed\n",
      "167 of 332 generic queries transformed\n",
      "168 of 332 generic queries transformed\n",
      "169 of 332 generic queries transformed\n",
      "170 of 332 generic queries transformed\n",
      "171 of 332 generic queries transformed\n",
      "172 of 332 generic queries transformed\n",
      "173 of 332 generic queries transformed\n",
      "174 of 332 generic queries transformed\n",
      "175 of 332 generic queries transformed\n",
      "176 of 332 generic queries transformed\n",
      "177 of 332 generic queries transformed\n",
      "178 of 332 generic queries transformed\n",
      "179 of 332 generic queries transformed\n",
      "180 of 332 generic queries transformed\n",
      "181 of 332 generic queries transformed\n",
      "182 of 332 generic queries transformed\n",
      "183 of 332 generic queries transformed\n",
      "184 of 332 generic queries transformed\n",
      "185 of 332 generic queries transformed\n",
      "186 of 332 generic queries transformed\n",
      "187 of 332 generic queries transformed\n",
      "188 of 332 generic queries transformed\n",
      "189 of 332 generic queries transformed\n",
      "190 of 332 generic queries transformed\n",
      "191 of 332 generic queries transformed\n",
      "192 of 332 generic queries transformed\n",
      "193 of 332 generic queries transformed\n",
      "194 of 332 generic queries transformed\n",
      "195 of 332 generic queries transformed\n",
      "196 of 332 generic queries transformed\n",
      "197 of 332 generic queries transformed\n",
      "198 of 332 generic queries transformed\n",
      "199 of 332 generic queries transformed\n",
      "200 of 332 generic queries transformed\n",
      "201 of 332 generic queries transformed\n",
      "202 of 332 generic queries transformed\n",
      "203 of 332 generic queries transformed\n",
      "204 of 332 generic queries transformed\n",
      "205 of 332 generic queries transformed\n",
      "206 of 332 generic queries transformed\n",
      "207 of 332 generic queries transformed\n",
      "208 of 332 generic queries transformed\n",
      "209 of 332 generic queries transformed\n",
      "210 of 332 generic queries transformed\n",
      "211 of 332 generic queries transformed\n",
      "212 of 332 generic queries transformed\n",
      "213 of 332 generic queries transformed\n",
      "214 of 332 generic queries transformed\n",
      "215 of 332 generic queries transformed\n",
      "216 of 332 generic queries transformed\n",
      "217 of 332 generic queries transformed\n",
      "218 of 332 generic queries transformed\n",
      "219 of 332 generic queries transformed\n",
      "220 of 332 generic queries transformed\n",
      "221 of 332 generic queries transformed\n",
      "222 of 332 generic queries transformed\n",
      "223 of 332 generic queries transformed\n",
      "224 of 332 generic queries transformed\n",
      "225 of 332 generic queries transformed\n",
      "226 of 332 generic queries transformed\n",
      "227 of 332 generic queries transformed\n",
      "228 of 332 generic queries transformed\n",
      "229 of 332 generic queries transformed\n",
      "230 of 332 generic queries transformed\n",
      "231 of 332 generic queries transformed\n",
      "232 of 332 generic queries transformed\n",
      "233 of 332 generic queries transformed\n",
      "234 of 332 generic queries transformed\n",
      "235 of 332 generic queries transformed\n",
      "236 of 332 generic queries transformed\n",
      "237 of 332 generic queries transformed\n",
      "238 of 332 generic queries transformed\n",
      "239 of 332 generic queries transformed\n",
      "240 of 332 generic queries transformed\n",
      "241 of 332 generic queries transformed\n",
      "242 of 332 generic queries transformed\n",
      "243 of 332 generic queries transformed\n",
      "244 of 332 generic queries transformed\n",
      "245 of 332 generic queries transformed\n",
      "246 of 332 generic queries transformed\n",
      "247 of 332 generic queries transformed\n",
      "248 of 332 generic queries transformed\n",
      "249 of 332 generic queries transformed\n",
      "250 of 332 generic queries transformed\n",
      "251 of 332 generic queries transformed\n",
      "252 of 332 generic queries transformed\n",
      "253 of 332 generic queries transformed\n",
      "254 of 332 generic queries transformed\n",
      "255 of 332 generic queries transformed\n",
      "256 of 332 generic queries transformed\n",
      "257 of 332 generic queries transformed\n",
      "258 of 332 generic queries transformed\n",
      "259 of 332 generic queries transformed\n",
      "260 of 332 generic queries transformed\n",
      "261 of 332 generic queries transformed\n",
      "262 of 332 generic queries transformed\n",
      "263 of 332 generic queries transformed\n",
      "264 of 332 generic queries transformed\n",
      "265 of 332 generic queries transformed\n",
      "266 of 332 generic queries transformed\n",
      "267 of 332 generic queries transformed\n",
      "268 of 332 generic queries transformed\n",
      "269 of 332 generic queries transformed\n",
      "270 of 332 generic queries transformed\n",
      "271 of 332 generic queries transformed\n",
      "272 of 332 generic queries transformed\n",
      "273 of 332 generic queries transformed\n",
      "274 of 332 generic queries transformed\n",
      "275 of 332 generic queries transformed\n",
      "276 of 332 generic queries transformed\n",
      "277 of 332 generic queries transformed\n",
      "278 of 332 generic queries transformed\n",
      "279 of 332 generic queries transformed\n",
      "280 of 332 generic queries transformed\n",
      "281 of 332 generic queries transformed\n",
      "282 of 332 generic queries transformed\n",
      "283 of 332 generic queries transformed\n",
      "284 of 332 generic queries transformed\n",
      "285 of 332 generic queries transformed\n",
      "286 of 332 generic queries transformed\n",
      "287 of 332 generic queries transformed\n",
      "288 of 332 generic queries transformed\n",
      "289 of 332 generic queries transformed\n",
      "290 of 332 generic queries transformed\n",
      "291 of 332 generic queries transformed\n",
      "292 of 332 generic queries transformed\n",
      "293 of 332 generic queries transformed\n",
      "294 of 332 generic queries transformed\n",
      "295 of 332 generic queries transformed\n",
      "296 of 332 generic queries transformed\n",
      "297 of 332 generic queries transformed\n",
      "298 of 332 generic queries transformed\n",
      "299 of 332 generic queries transformed\n",
      "300 of 332 generic queries transformed\n",
      "301 of 332 generic queries transformed\n",
      "302 of 332 generic queries transformed\n",
      "303 of 332 generic queries transformed\n",
      "304 of 332 generic queries transformed\n",
      "305 of 332 generic queries transformed\n",
      "306 of 332 generic queries transformed\n",
      "307 of 332 generic queries transformed\n",
      "308 of 332 generic queries transformed\n",
      "309 of 332 generic queries transformed\n",
      "310 of 332 generic queries transformed\n",
      "311 of 332 generic queries transformed\n",
      "312 of 332 generic queries transformed\n",
      "313 of 332 generic queries transformed\n",
      "314 of 332 generic queries transformed\n",
      "315 of 332 generic queries transformed\n",
      "316 of 332 generic queries transformed\n",
      "317 of 332 generic queries transformed\n",
      "318 of 332 generic queries transformed\n",
      "319 of 332 generic queries transformed\n",
      "320 of 332 generic queries transformed\n",
      "321 of 332 generic queries transformed\n",
      "322 of 332 generic queries transformed\n",
      "323 of 332 generic queries transformed\n",
      "324 of 332 generic queries transformed\n",
      "325 of 332 generic queries transformed\n",
      "326 of 332 generic queries transformed\n",
      "327 of 332 generic queries transformed\n",
      "328 of 332 generic queries transformed\n",
      "329 of 332 generic queries transformed\n",
      "330 of 332 generic queries transformed\n",
      "331 of 332 generic queries transformed\n",
      "332 of 332 generic queries transformed\n",
      "generic objects transformation completed\n",
      "thesis queries generated\n",
      "321 queries of thesis objects to be transformed\n",
      "1 of 321 thesis queries transformed\n",
      "2 of 321 thesis queries transformed\n",
      "3 of 321 thesis queries transformed\n",
      "4 of 321 thesis queries transformed\n",
      "5 of 321 thesis queries transformed\n",
      "6 of 321 thesis queries transformed\n",
      "7 of 321 thesis queries transformed\n",
      "8 of 321 thesis queries transformed\n",
      "9 of 321 thesis queries transformed\n",
      "10 of 321 thesis queries transformed\n",
      "11 of 321 thesis queries transformed\n",
      "12 of 321 thesis queries transformed\n",
      "13 of 321 thesis queries transformed\n",
      "14 of 321 thesis queries transformed\n",
      "15 of 321 thesis queries transformed\n",
      "16 of 321 thesis queries transformed\n",
      "17 of 321 thesis queries transformed\n",
      "18 of 321 thesis queries transformed\n",
      "19 of 321 thesis queries transformed\n",
      "20 of 321 thesis queries transformed\n",
      "21 of 321 thesis queries transformed\n",
      "22 of 321 thesis queries transformed\n",
      "23 of 321 thesis queries transformed\n",
      "24 of 321 thesis queries transformed\n",
      "25 of 321 thesis queries transformed\n",
      "26 of 321 thesis queries transformed\n",
      "27 of 321 thesis queries transformed\n",
      "28 of 321 thesis queries transformed\n",
      "29 of 321 thesis queries transformed\n",
      "30 of 321 thesis queries transformed\n",
      "31 of 321 thesis queries transformed\n",
      "32 of 321 thesis queries transformed\n",
      "33 of 321 thesis queries transformed\n",
      "34 of 321 thesis queries transformed\n",
      "35 of 321 thesis queries transformed\n",
      "36 of 321 thesis queries transformed\n",
      "37 of 321 thesis queries transformed\n",
      "38 of 321 thesis queries transformed\n",
      "39 of 321 thesis queries transformed\n",
      "40 of 321 thesis queries transformed\n",
      "41 of 321 thesis queries transformed\n",
      "42 of 321 thesis queries transformed\n",
      "43 of 321 thesis queries transformed\n",
      "44 of 321 thesis queries transformed\n",
      "45 of 321 thesis queries transformed\n",
      "46 of 321 thesis queries transformed\n",
      "47 of 321 thesis queries transformed\n",
      "48 of 321 thesis queries transformed\n",
      "49 of 321 thesis queries transformed\n",
      "50 of 321 thesis queries transformed\n",
      "51 of 321 thesis queries transformed\n",
      "52 of 321 thesis queries transformed\n",
      "53 of 321 thesis queries transformed\n",
      "54 of 321 thesis queries transformed\n",
      "55 of 321 thesis queries transformed\n",
      "56 of 321 thesis queries transformed\n",
      "57 of 321 thesis queries transformed\n",
      "58 of 321 thesis queries transformed\n",
      "59 of 321 thesis queries transformed\n",
      "60 of 321 thesis queries transformed\n",
      "61 of 321 thesis queries transformed\n",
      "62 of 321 thesis queries transformed\n",
      "63 of 321 thesis queries transformed\n",
      "64 of 321 thesis queries transformed\n",
      "65 of 321 thesis queries transformed\n",
      "66 of 321 thesis queries transformed\n",
      "67 of 321 thesis queries transformed\n",
      "68 of 321 thesis queries transformed\n",
      "69 of 321 thesis queries transformed\n",
      "70 of 321 thesis queries transformed\n",
      "71 of 321 thesis queries transformed\n",
      "72 of 321 thesis queries transformed\n",
      "73 of 321 thesis queries transformed\n",
      "74 of 321 thesis queries transformed\n",
      "75 of 321 thesis queries transformed\n",
      "76 of 321 thesis queries transformed\n",
      "77 of 321 thesis queries transformed\n",
      "78 of 321 thesis queries transformed\n",
      "79 of 321 thesis queries transformed\n",
      "80 of 321 thesis queries transformed\n",
      "81 of 321 thesis queries transformed\n",
      "82 of 321 thesis queries transformed\n",
      "83 of 321 thesis queries transformed\n",
      "84 of 321 thesis queries transformed\n",
      "85 of 321 thesis queries transformed\n",
      "86 of 321 thesis queries transformed\n",
      "87 of 321 thesis queries transformed\n",
      "88 of 321 thesis queries transformed\n",
      "89 of 321 thesis queries transformed\n",
      "90 of 321 thesis queries transformed\n",
      "91 of 321 thesis queries transformed\n",
      "92 of 321 thesis queries transformed\n",
      "93 of 321 thesis queries transformed\n",
      "94 of 321 thesis queries transformed\n",
      "95 of 321 thesis queries transformed\n",
      "96 of 321 thesis queries transformed\n",
      "97 of 321 thesis queries transformed\n",
      "98 of 321 thesis queries transformed\n",
      "99 of 321 thesis queries transformed\n",
      "100 of 321 thesis queries transformed\n",
      "101 of 321 thesis queries transformed\n",
      "102 of 321 thesis queries transformed\n",
      "103 of 321 thesis queries transformed\n",
      "104 of 321 thesis queries transformed\n",
      "105 of 321 thesis queries transformed\n",
      "106 of 321 thesis queries transformed\n",
      "107 of 321 thesis queries transformed\n",
      "108 of 321 thesis queries transformed\n",
      "109 of 321 thesis queries transformed\n",
      "110 of 321 thesis queries transformed\n",
      "111 of 321 thesis queries transformed\n",
      "112 of 321 thesis queries transformed\n",
      "113 of 321 thesis queries transformed\n",
      "114 of 321 thesis queries transformed\n",
      "115 of 321 thesis queries transformed\n",
      "116 of 321 thesis queries transformed\n",
      "117 of 321 thesis queries transformed\n",
      "118 of 321 thesis queries transformed\n",
      "119 of 321 thesis queries transformed\n",
      "120 of 321 thesis queries transformed\n",
      "121 of 321 thesis queries transformed\n",
      "122 of 321 thesis queries transformed\n",
      "123 of 321 thesis queries transformed\n",
      "124 of 321 thesis queries transformed\n",
      "125 of 321 thesis queries transformed\n",
      "126 of 321 thesis queries transformed\n",
      "127 of 321 thesis queries transformed\n",
      "128 of 321 thesis queries transformed\n",
      "129 of 321 thesis queries transformed\n",
      "130 of 321 thesis queries transformed\n",
      "131 of 321 thesis queries transformed\n",
      "132 of 321 thesis queries transformed\n",
      "133 of 321 thesis queries transformed\n",
      "134 of 321 thesis queries transformed\n",
      "135 of 321 thesis queries transformed\n",
      "136 of 321 thesis queries transformed\n",
      "137 of 321 thesis queries transformed\n",
      "138 of 321 thesis queries transformed\n",
      "139 of 321 thesis queries transformed\n",
      "140 of 321 thesis queries transformed\n",
      "141 of 321 thesis queries transformed\n",
      "142 of 321 thesis queries transformed\n",
      "143 of 321 thesis queries transformed\n",
      "144 of 321 thesis queries transformed\n",
      "145 of 321 thesis queries transformed\n",
      "146 of 321 thesis queries transformed\n",
      "147 of 321 thesis queries transformed\n",
      "148 of 321 thesis queries transformed\n",
      "149 of 321 thesis queries transformed\n",
      "150 of 321 thesis queries transformed\n",
      "151 of 321 thesis queries transformed\n",
      "152 of 321 thesis queries transformed\n",
      "153 of 321 thesis queries transformed\n",
      "154 of 321 thesis queries transformed\n",
      "155 of 321 thesis queries transformed\n",
      "156 of 321 thesis queries transformed\n",
      "157 of 321 thesis queries transformed\n",
      "158 of 321 thesis queries transformed\n",
      "159 of 321 thesis queries transformed\n",
      "160 of 321 thesis queries transformed\n",
      "161 of 321 thesis queries transformed\n",
      "162 of 321 thesis queries transformed\n",
      "163 of 321 thesis queries transformed\n",
      "164 of 321 thesis queries transformed\n",
      "165 of 321 thesis queries transformed\n",
      "166 of 321 thesis queries transformed\n",
      "167 of 321 thesis queries transformed\n",
      "168 of 321 thesis queries transformed\n",
      "169 of 321 thesis queries transformed\n",
      "170 of 321 thesis queries transformed\n",
      "171 of 321 thesis queries transformed\n",
      "172 of 321 thesis queries transformed\n",
      "173 of 321 thesis queries transformed\n",
      "174 of 321 thesis queries transformed\n",
      "175 of 321 thesis queries transformed\n",
      "176 of 321 thesis queries transformed\n",
      "177 of 321 thesis queries transformed\n",
      "178 of 321 thesis queries transformed\n",
      "179 of 321 thesis queries transformed\n",
      "180 of 321 thesis queries transformed\n",
      "181 of 321 thesis queries transformed\n",
      "182 of 321 thesis queries transformed\n",
      "183 of 321 thesis queries transformed\n",
      "184 of 321 thesis queries transformed\n",
      "185 of 321 thesis queries transformed\n",
      "186 of 321 thesis queries transformed\n",
      "187 of 321 thesis queries transformed\n",
      "188 of 321 thesis queries transformed\n",
      "189 of 321 thesis queries transformed\n",
      "190 of 321 thesis queries transformed\n",
      "191 of 321 thesis queries transformed\n",
      "192 of 321 thesis queries transformed\n",
      "193 of 321 thesis queries transformed\n",
      "194 of 321 thesis queries transformed\n",
      "195 of 321 thesis queries transformed\n",
      "196 of 321 thesis queries transformed\n",
      "197 of 321 thesis queries transformed\n",
      "198 of 321 thesis queries transformed\n",
      "199 of 321 thesis queries transformed\n",
      "200 of 321 thesis queries transformed\n",
      "201 of 321 thesis queries transformed\n",
      "202 of 321 thesis queries transformed\n",
      "203 of 321 thesis queries transformed\n",
      "204 of 321 thesis queries transformed\n",
      "205 of 321 thesis queries transformed\n",
      "206 of 321 thesis queries transformed\n",
      "207 of 321 thesis queries transformed\n",
      "208 of 321 thesis queries transformed\n",
      "209 of 321 thesis queries transformed\n",
      "210 of 321 thesis queries transformed\n",
      "211 of 321 thesis queries transformed\n",
      "212 of 321 thesis queries transformed\n",
      "213 of 321 thesis queries transformed\n",
      "214 of 321 thesis queries transformed\n",
      "215 of 321 thesis queries transformed\n",
      "216 of 321 thesis queries transformed\n",
      "217 of 321 thesis queries transformed\n",
      "218 of 321 thesis queries transformed\n",
      "219 of 321 thesis queries transformed\n",
      "220 of 321 thesis queries transformed\n",
      "221 of 321 thesis queries transformed\n",
      "222 of 321 thesis queries transformed\n",
      "223 of 321 thesis queries transformed\n",
      "224 of 321 thesis queries transformed\n",
      "225 of 321 thesis queries transformed\n",
      "226 of 321 thesis queries transformed\n",
      "227 of 321 thesis queries transformed\n",
      "228 of 321 thesis queries transformed\n",
      "229 of 321 thesis queries transformed\n",
      "230 of 321 thesis queries transformed\n",
      "231 of 321 thesis queries transformed\n",
      "232 of 321 thesis queries transformed\n",
      "233 of 321 thesis queries transformed\n",
      "234 of 321 thesis queries transformed\n",
      "235 of 321 thesis queries transformed\n",
      "236 of 321 thesis queries transformed\n",
      "237 of 321 thesis queries transformed\n",
      "238 of 321 thesis queries transformed\n",
      "239 of 321 thesis queries transformed\n",
      "240 of 321 thesis queries transformed\n",
      "241 of 321 thesis queries transformed\n",
      "242 of 321 thesis queries transformed\n",
      "243 of 321 thesis queries transformed\n",
      "244 of 321 thesis queries transformed\n",
      "245 of 321 thesis queries transformed\n",
      "246 of 321 thesis queries transformed\n",
      "247 of 321 thesis queries transformed\n",
      "248 of 321 thesis queries transformed\n",
      "249 of 321 thesis queries transformed\n",
      "250 of 321 thesis queries transformed\n",
      "251 of 321 thesis queries transformed\n",
      "252 of 321 thesis queries transformed\n",
      "253 of 321 thesis queries transformed\n",
      "254 of 321 thesis queries transformed\n",
      "255 of 321 thesis queries transformed\n",
      "256 of 321 thesis queries transformed\n",
      "257 of 321 thesis queries transformed\n",
      "258 of 321 thesis queries transformed\n",
      "259 of 321 thesis queries transformed\n",
      "260 of 321 thesis queries transformed\n",
      "261 of 321 thesis queries transformed\n",
      "262 of 321 thesis queries transformed\n",
      "263 of 321 thesis queries transformed\n",
      "264 of 321 thesis queries transformed\n",
      "265 of 321 thesis queries transformed\n",
      "266 of 321 thesis queries transformed\n",
      "267 of 321 thesis queries transformed\n",
      "268 of 321 thesis queries transformed\n",
      "269 of 321 thesis queries transformed\n",
      "270 of 321 thesis queries transformed\n",
      "271 of 321 thesis queries transformed\n",
      "272 of 321 thesis queries transformed\n",
      "273 of 321 thesis queries transformed\n",
      "274 of 321 thesis queries transformed\n",
      "275 of 321 thesis queries transformed\n",
      "276 of 321 thesis queries transformed\n",
      "277 of 321 thesis queries transformed\n",
      "278 of 321 thesis queries transformed\n",
      "279 of 321 thesis queries transformed\n",
      "280 of 321 thesis queries transformed\n",
      "281 of 321 thesis queries transformed\n",
      "282 of 321 thesis queries transformed\n",
      "283 of 321 thesis queries transformed\n",
      "284 of 321 thesis queries transformed\n",
      "285 of 321 thesis queries transformed\n",
      "286 of 321 thesis queries transformed\n",
      "287 of 321 thesis queries transformed\n",
      "288 of 321 thesis queries transformed\n",
      "289 of 321 thesis queries transformed\n",
      "290 of 321 thesis queries transformed\n",
      "291 of 321 thesis queries transformed\n",
      "292 of 321 thesis queries transformed\n",
      "293 of 321 thesis queries transformed\n",
      "294 of 321 thesis queries transformed\n",
      "295 of 321 thesis queries transformed\n",
      "296 of 321 thesis queries transformed\n",
      "297 of 321 thesis queries transformed\n",
      "298 of 321 thesis queries transformed\n",
      "299 of 321 thesis queries transformed\n",
      "300 of 321 thesis queries transformed\n",
      "301 of 321 thesis queries transformed\n",
      "302 of 321 thesis queries transformed\n",
      "303 of 321 thesis queries transformed\n",
      "304 of 321 thesis queries transformed\n",
      "305 of 321 thesis queries transformed\n",
      "306 of 321 thesis queries transformed\n",
      "307 of 321 thesis queries transformed\n",
      "308 of 321 thesis queries transformed\n",
      "309 of 321 thesis queries transformed\n",
      "310 of 321 thesis queries transformed\n",
      "311 of 321 thesis queries transformed\n",
      "312 of 321 thesis queries transformed\n",
      "313 of 321 thesis queries transformed\n",
      "314 of 321 thesis queries transformed\n",
      "315 of 321 thesis queries transformed\n",
      "316 of 321 thesis queries transformed\n",
      "317 of 321 thesis queries transformed\n",
      "318 of 321 thesis queries transformed\n",
      "319 of 321 thesis queries transformed\n",
      "320 of 321 thesis queries transformed\n",
      "321 of 321 thesis queries transformed\n",
      "thesis objects transformation completed\n",
      "era1statsFile queries generated\n",
      "304 queries of era1statsFile objects to be transformed\n",
      "1 of 304 era1statsFile queries transformed\n",
      "2 of 304 era1statsFile queries transformed\n",
      "3 of 304 era1statsFile queries transformed\n",
      "4 of 304 era1statsFile queries transformed\n",
      "5 of 304 era1statsFile queries transformed\n",
      "6 of 304 era1statsFile queries transformed\n",
      "7 of 304 era1statsFile queries transformed\n",
      "8 of 304 era1statsFile queries transformed\n",
      "9 of 304 era1statsFile queries transformed\n",
      "10 of 304 era1statsFile queries transformed\n",
      "11 of 304 era1statsFile queries transformed\n",
      "12 of 304 era1statsFile queries transformed\n",
      "13 of 304 era1statsFile queries transformed\n",
      "14 of 304 era1statsFile queries transformed\n",
      "15 of 304 era1statsFile queries transformed\n",
      "16 of 304 era1statsFile queries transformed\n",
      "17 of 304 era1statsFile queries transformed\n",
      "18 of 304 era1statsFile queries transformed\n",
      "19 of 304 era1statsFile queries transformed\n",
      "20 of 304 era1statsFile queries transformed\n",
      "21 of 304 era1statsFile queries transformed\n",
      "22 of 304 era1statsFile queries transformed\n",
      "23 of 304 era1statsFile queries transformed\n",
      "24 of 304 era1statsFile queries transformed\n",
      "25 of 304 era1statsFile queries transformed\n",
      "26 of 304 era1statsFile queries transformed\n",
      "27 of 304 era1statsFile queries transformed\n",
      "28 of 304 era1statsFile queries transformed\n",
      "29 of 304 era1statsFile queries transformed\n",
      "30 of 304 era1statsFile queries transformed\n",
      "31 of 304 era1statsFile queries transformed\n",
      "32 of 304 era1statsFile queries transformed\n",
      "33 of 304 era1statsFile queries transformed\n",
      "34 of 304 era1statsFile queries transformed\n",
      "35 of 304 era1statsFile queries transformed\n",
      "36 of 304 era1statsFile queries transformed\n",
      "37 of 304 era1statsFile queries transformed\n",
      "38 of 304 era1statsFile queries transformed\n",
      "39 of 304 era1statsFile queries transformed\n",
      "40 of 304 era1statsFile queries transformed\n",
      "41 of 304 era1statsFile queries transformed\n",
      "42 of 304 era1statsFile queries transformed\n",
      "43 of 304 era1statsFile queries transformed\n",
      "44 of 304 era1statsFile queries transformed\n",
      "45 of 304 era1statsFile queries transformed\n",
      "46 of 304 era1statsFile queries transformed\n",
      "47 of 304 era1statsFile queries transformed\n",
      "48 of 304 era1statsFile queries transformed\n",
      "49 of 304 era1statsFile queries transformed\n",
      "50 of 304 era1statsFile queries transformed\n",
      "51 of 304 era1statsFile queries transformed\n",
      "52 of 304 era1statsFile queries transformed\n",
      "53 of 304 era1statsFile queries transformed\n",
      "54 of 304 era1statsFile queries transformed\n",
      "55 of 304 era1statsFile queries transformed\n",
      "56 of 304 era1statsFile queries transformed\n",
      "57 of 304 era1statsFile queries transformed\n",
      "58 of 304 era1statsFile queries transformed\n",
      "59 of 304 era1statsFile queries transformed\n",
      "60 of 304 era1statsFile queries transformed\n",
      "61 of 304 era1statsFile queries transformed\n",
      "62 of 304 era1statsFile queries transformed\n",
      "63 of 304 era1statsFile queries transformed\n",
      "64 of 304 era1statsFile queries transformed\n",
      "65 of 304 era1statsFile queries transformed\n",
      "66 of 304 era1statsFile queries transformed\n",
      "67 of 304 era1statsFile queries transformed\n",
      "68 of 304 era1statsFile queries transformed\n",
      "69 of 304 era1statsFile queries transformed\n",
      "70 of 304 era1statsFile queries transformed\n",
      "71 of 304 era1statsFile queries transformed\n",
      "72 of 304 era1statsFile queries transformed\n",
      "73 of 304 era1statsFile queries transformed\n",
      "74 of 304 era1statsFile queries transformed\n",
      "75 of 304 era1statsFile queries transformed\n",
      "76 of 304 era1statsFile queries transformed\n",
      "77 of 304 era1statsFile queries transformed\n",
      "78 of 304 era1statsFile queries transformed\n",
      "79 of 304 era1statsFile queries transformed\n",
      "80 of 304 era1statsFile queries transformed\n",
      "81 of 304 era1statsFile queries transformed\n",
      "82 of 304 era1statsFile queries transformed\n",
      "83 of 304 era1statsFile queries transformed\n",
      "84 of 304 era1statsFile queries transformed\n",
      "85 of 304 era1statsFile queries transformed\n",
      "86 of 304 era1statsFile queries transformed\n",
      "87 of 304 era1statsFile queries transformed\n",
      "88 of 304 era1statsFile queries transformed\n",
      "89 of 304 era1statsFile queries transformed\n",
      "90 of 304 era1statsFile queries transformed\n",
      "91 of 304 era1statsFile queries transformed\n",
      "92 of 304 era1statsFile queries transformed\n",
      "93 of 304 era1statsFile queries transformed\n",
      "94 of 304 era1statsFile queries transformed\n",
      "95 of 304 era1statsFile queries transformed\n",
      "96 of 304 era1statsFile queries transformed\n",
      "97 of 304 era1statsFile queries transformed\n",
      "98 of 304 era1statsFile queries transformed\n",
      "99 of 304 era1statsFile queries transformed\n",
      "100 of 304 era1statsFile queries transformed\n",
      "101 of 304 era1statsFile queries transformed\n",
      "102 of 304 era1statsFile queries transformed\n",
      "103 of 304 era1statsFile queries transformed\n",
      "104 of 304 era1statsFile queries transformed\n",
      "105 of 304 era1statsFile queries transformed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-a321337e7e06>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mfuture_to_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparellelTransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueryObject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqueryObject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuture_to_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuture_to_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zschoenb/Programs/conda/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mas_completed\u001b[1;34m(fs, timeout)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m             \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zschoenb/Programs/conda/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zschoenb/Programs/conda/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-aa7afb95b669>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m         \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-74-a321337e7e06>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%i of %i %s queries transformed\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueryObject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjectType\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                     \u001b[0mPrintException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;31m#queryObject.postResults()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s objects transformation completed\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mobjectType\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zschoenb/Programs/conda/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zschoenb/Programs/conda/lib/python3.5/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[1;34m(self, wait)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                 \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zschoenb/Programs/conda/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[1;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zschoenb/Programs/conda/lib/python3.5/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# already determined that the C code is done\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1070\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1071\u001b[0m             \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
